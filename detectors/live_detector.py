import os
import logging
import numpy as np
import torch
from sklearn.preprocessing import MinMaxScaler
from models.model import LSTMAutoencoder
from logs.log_config import setup_logger
from logs.shared_log import log_buffer

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ì„¤ì • ë° ì´ˆê¸°í™” â€”â€”â€”â€”â€”â€”â€”â€”â€”
setup_logger()
logging.info("ğŸ”„ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì¤‘...")

SEQ_LEN       = 60
VOL_Z_THRESH  = 4.0       # ë³¼ë¥¨ ë¡œê·¸-z ìŠ¤ì½”ì–´ ì„ê³„ì¹˜
PRICE_RET_TH  = 0.005     # ì¢…ê°€ ë³€í™”ìœ¨ ì„ê³„ì¹˜ (0.5%)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
logging.info(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {DEVICE}")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ëª¨ë¸ ë¡œë“œ â€”â€”â€”â€”â€”â€”â€”â€”â€”
model = LSTMAutoencoder(input_dim=5,
                        seq_len=SEQ_LEN,
                        hidden1=128,
                        hidden2=64,
                        latent=32).to(DEVICE)

model_path = "models/best_lstm_autoencoder.pt"
model.load_state_dict(torch.load(model_path, map_location=DEVICE))
model.eval()
logging.info(f"âœ… LSTM Autoencoder ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({model_path})")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ â€”â€”â€”â€”â€”â€”â€”â€”â€”
min_vals, max_vals = np.load("models/minmax_scaler.npy", allow_pickle=True)
scaler = MinMaxScaler()
# MinMaxScaler ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì§ì ‘ ì„¤ì •
scaler.min_, scaler.scale_     = 0, 1 / (max_vals - min_vals + 1e-8)
scaler.data_min_, scaler.data_max_ = min_vals, max_vals
logging.info("âœ… MinMaxScaler íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” IQR ì„ê³„ì¹˜ ê³„ì‚° â€”â€”â€”â€”â€”â€”â€”â€”â€”
train_errors = np.load("models/train_recon_errors.npy")
q1, q3       = np.percentile(train_errors, [25, 75])
iqr          = q3 - q1
lower_thres  = q1 - 2.0 * iqr
upper_thres  = q3 + 2.0 * iqr
logging.info(f"âœ… IQR ì„ê³„ì¹˜ ì„¤ì • ì™„ë£Œ | lower: {lower_thres:.6f}, upper: {upper_thres:.6f}")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ì‹¤ì‹œê°„ ìœˆë„ìš° ë²„í¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”
window = []

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ì´ìƒ íƒì§€ í•¨ìˆ˜ â€”â€”â€”â€”â€”â€”â€”â€”â€”
def detect_anomaly(new_candle: np.ndarray):
    """
    new_candle: [open, high, low, close, volume] ìˆœì˜ 1D numpy array
    """
    global window
    window.append(new_candle)

    # ìœˆë„ìš°ê°€ ì°¨ê¸° ì „ê¹Œì§€ëŠ” íƒì§€í•˜ì§€ ì•ŠìŒ
    if len(window) < SEQ_LEN + 1:
        logging.info(f"ğŸ“‰ ìº”ë“¤ ìˆ˜ì‹  (ìœˆë„ìš° ê¸¸ì´: {len(window)}) â€” ëŒ€ê¸° ì¤‘")
        return

    # 1) ëª¨ë¸ ê¸°ë°˜ ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°
    arr       = np.array(window)
    diffed    = np.diff(arr, axis=0)               # ì°¨ë¶„
    seq       = diffed[-SEQ_LEN:]                  # ë§ˆì§€ë§‰ SEQ_LENê°œ
    scaled    = scaler.transform(seq)              # ì •ê·œí™”
    x_tensor  = torch.tensor(scaled, dtype=torch.float32)\
                    .unsqueeze(0).to(DEVICE)      # (1, SEQ_LEN, 5)
    with torch.no_grad():
        recon    = model(x_tensor)
    mae_error = torch.mean(torch.abs(recon - x_tensor)).item()
    iqr_anomaly = (mae_error < lower_thres) or (mae_error > upper_thres)

    # 2) ë³¼ë¥¨ ìŠ¤íŒŒì´í¬ + ì¢…ê°€ ë³€í™”ìœ¨ ê³„ì‚°
    vols      = arr[-SEQ_LEN:, 4]                  # ìµœê·¼ SEQ_LEN ê±°ë˜ëŸ‰
    log_vols  = np.log1p(vols)
    mu, sigma = log_vols.mean(), log_vols.std(ddof=0)
    last_log  = np.log1p(arr[-1, 4])
    z_score   = (last_log - mu) / (sigma + 1e-8)

    prev_close = arr[-2, 3]
    last_close = arr[-1, 3]
    price_ret  = (last_close - prev_close) / (prev_close + 1e-8)

    vol_spike           = abs(z_score) > VOL_Z_THRESH
    price_spike         = abs(price_ret) > PRICE_RET_TH
    vol_price_anomaly   = vol_spike and price_spike

    # 3) ìµœì¢… ì´ìƒì¹˜ íŒì •: IQR ëª¨ë¸ OR (ë³¼ë¥¨+ì¢…ê°€ ìŠ¤íŒŒì´í¬)
    final_anomaly = iqr_anomaly or vol_price_anomaly

    # 4) ë¡œê·¸ ë²„í¼ì— ì €ì¥ (FastAPI â†’ í”„ë¡ íŠ¸ì—”ë“œ)
    log_msg = {
        "mae":               mae_error,
        "iqr_anomaly":       bool(iqr_anomaly),
        "vol_z_score":       float(z_score),
        "price_ret":         float(price_ret),
        "vol_price_anomaly": bool(vol_price_anomaly),
        "anomaly":           final_anomaly
    }
    log_buffer.append(log_msg)

    # 5) ì½˜ì†” ì¶œë ¥
    if final_anomaly:
        logging.warning(
            f"ğŸš¨ ì´ìƒì¹˜ ê°ì§€! MAE={mae_error:.6f} | "
            f"vol_z={z_score:.2f} | ret={price_ret*100:.2f}%"
        )
    else:
        logging.info(f"âœ… ì •ìƒ ìº”ë“¤ | MAE={mae_error:.6f}")

    # 6) ìœˆë„ìš° ìŠ¬ë¼ì´ë“œ
    window.pop(0)

