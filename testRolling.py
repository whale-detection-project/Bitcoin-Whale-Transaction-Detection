import os
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from sklearn.preprocessing import MinMaxScaler
from models.model import LSTMAutoencoder
from logs.log_config import setup_logger
from logs.shared_log import log_buffer

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ì„¤ì • ë° ì´ˆê¸°í™” â€”â€”â€”â€”â€”â€”â€”â€”â€”
setup_logger()
logging.info("ğŸ”„ ë°±í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (Rolling IQR) ì‹œì‘")

# íŒŒë¼ë¯¸í„°
CSV_PATH        = "BTCUSDT_2025.csv"
SEQ_LEN         = 60
VOL_Z_THRESH    = 4.0       # ë¡œê·¸-z ì„ê³„ì¹˜
PRICE_RET_TH    = 0.005     # ì¢…ê°€ ë³€í™”ìœ¨ ì„ê³„ì¹˜
ROLLING_WINDOW  = 720       # ìµœê·¼ MAE ëª‡ ê°œë¡œ IQR ê³„ì‚°í• ì§€
DEVICE          = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ëª¨ë¸ & ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ â€”â€”â€”â€”â€”â€”â€”â€”â€”
model = LSTMAutoencoder(input_dim=5, seq_len=SEQ_LEN, hidden1=128, hidden2=64, latent=32)
model.load_state_dict(torch.load("models/best_lstm_autoencoder.pt", map_location=DEVICE))
model.to(DEVICE).eval()
logging.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

min_vals, max_vals = np.load("models/minmax_scaler.npy", allow_pickle=True)
scaler = MinMaxScaler()
scaler.min_, scaler.scale_       = 0, 1/(max_vals - min_vals + 1e-8)
scaler.data_min_, scaler.data_max_ = min_vals, max_vals
logging.info("âœ… Scaler íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” CSV ë¡œë“œ â€”â€”â€”â€”â€”â€”â€”â€”â€”
if not os.path.exists(CSV_PATH):
    CSV_PATH = os.path.join("data", CSV_PATH)
df = pd.read_csv(CSV_PATH, parse_dates=["timestamp"])
df.set_index("timestamp", inplace=True)
logging.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ì´ìƒì¹˜ íƒì§€ ë°±í…ŒìŠ¤íŠ¸ (Rolling IQR) â€”â€”â€”â€”â€”â€”â€”â€”â€”
results = []
window = []
mae_history = []  # ìµœê·¼ MAE ë²„í¼

for ts, row in df.iterrows():
    candle = row[['open','high','low','close','volume']].values
    window.append(candle)

    # ìœˆë„ìš°ê°€ ì°¨ê¸° ì „ê¹Œì§€ ìŠ¤í‚µ
    if len(window) < SEQ_LEN + 1:
        results.append({
            'timestamp': ts,
            'close': row['close'],
            'mae': np.nan,
            'rolling_lower': np.nan,
            'rolling_upper': np.nan,
            'iqr_anomaly': False,
            'vol_price_anomaly': False,
            'anomaly': False
        })
        continue

    arr = np.array(window[-(SEQ_LEN+1):])

    # â€” 1) ëª¨ë¸ ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°
    diffed    = np.diff(arr, axis=0)[-SEQ_LEN:]
    scaled    = scaler.transform(diffed)
    x_tensor  = torch.tensor(scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        recon = model(x_tensor)
    mae = torch.mean(torch.abs(recon - x_tensor)).item()

    # â€” 2) MAE íˆìŠ¤í† ë¦¬ì— ì¶”ê°€, ì˜¤ë˜ëœ ê±´ ì œê±°
    mae_history.append(mae)
    if len(mae_history) > ROLLING_WINDOW:
        mae_history.pop(0)

    # â€” 3) ë¡¤ë§ IQR ê³„ì‚° (ì¶©ë¶„íˆ ìŒ“ì¸ ì´í›„ë¶€í„°)
    if len(mae_history) >= 10:
        q1, q3 = np.percentile(mae_history, [25, 75])
        iqr    = q3 - q1
        lower  = q1 - 2.0 * iqr
        upper  = q3 + 2.0 * iqr
    else:
        # ì´ˆê¸°ì—” static IQR ì‚¬ìš©
        static_q1, static_q3 = np.percentile(np.load("models/train_recon_errors.npy"), [25, 75])
        static_iqr = static_q3 - static_q1
        lower      = static_q1 - 2.0 * static_iqr
        upper      = static_q3 + 2.0 * static_iqr

    iqr_anom = (mae < lower) or (mae > upper)

    # â€” 4) ë³¼ë¥¨+ê°€ê²© ìŠ¤íŒŒì´í¬
    vols      = arr[-SEQ_LEN:, 4]
    log_vols  = np.log1p(vols)
    mu, sigma = log_vols.mean(), log_vols.std(ddof=0)
    z_score   = (np.log1p(arr[-1, 4]) - mu) / (sigma + 1e-8)

    prev_c    = arr[-2, 3]
    last_c    = arr[-1, 3]
    price_ret = (last_c - prev_c) / (prev_c + 1e-8)

    vol_spike        = abs(z_score) > VOL_Z_THRESH
    price_spike      = abs(price_ret) > PRICE_RET_TH
    vol_price_anom   = vol_spike and price_spike

    final_anom = iqr_anom or vol_price_anom

    results.append({
        'timestamp': ts,
        'close': last_c,
        'mae': mae,
        'rolling_lower': lower,
        'rolling_upper': upper,
        'iqr_anomaly': iqr_anom,
        'vol_price_anomaly': vol_price_anom,
        'anomaly': final_anom
    })

    window.pop(0)

# â€”â€”â€”â€”â€”â€”â€” DataFrame & ì‹œê°í™” â€”â€”â€”â€”â€”â€”â€”
res_df = pd.DataFrame(results).set_index('timestamp')

# IQR ì´ìƒì¹˜ ê°œìˆ˜ ë¡œê¹…
iqr_count = int(res_df['iqr_anomaly'].sum())
logging.info(f"ğŸ” Rolling IQR ì´ìƒì¹˜ ê°œìˆ˜: {iqr_count}")

# ë³¼ë¥¨+ê°€ê²© ì´ìƒì¹˜ ê°œìˆ˜ ë¡œê¹…
vol_count = int(res_df['vol_price_anomaly'].sum())
logging.info(f"ğŸ” ë³¼ë¥¨+ê°€ê²© ì´ìƒì¹˜ ê°œìˆ˜: {vol_count}")

# 1) Rolling IQR ì´ìƒì¹˜ë§Œ
plt.figure(figsize=(12,6))
plt.plot(res_df.index, res_df['close'], alpha=0.6, label='Close')
mask_iqr = res_df['iqr_anomaly']
plt.scatter(
    res_df.index[mask_iqr],
    res_df['close'][mask_iqr],
    color='blue', s=10, marker='o',
    label=f'Rolling IQR Anomaly ({iqr_count})'
)
plt.title("BTC 2025 â€” Rolling IQR ê¸°ë°˜ ì´ìƒì¹˜")
plt.xlabel("Time"); plt.ylabel("Close Price")
plt.legend(); plt.tight_layout(); plt.show()

# 2) ë³¼ë¥¨ìŠ¤íŒŒì´í¬ + ê°€ê²©ë³€ë™ ì´ìƒì¹˜ë§Œ
plt.figure(figsize=(12,6))
plt.plot(res_df.index, res_df['close'], alpha=0.6, label='Close')
mask_vol = res_df['vol_price_anomaly']
plt.scatter(
    res_df.index[mask_vol],
    res_df['close'][mask_vol],
    color='orange', s=10, marker='x',
    label=f'Volume+Price Spike ({vol_count})'
)
plt.title("BTC 2025 â€” Volume Spike + Price Move ì´ìƒì¹˜")
plt.xlabel("Time"); plt.ylabel("Close Price")
plt.legend(); plt.tight_layout(); plt.show()

# â€”â€”â€”â€”â€”â€”â€” ê²°ê³¼ ìš”ì•½ â€”â€”â€”â€”â€”â€”â€”
total = len(res_df)
anom  = res_df['anomaly'].sum()
logging.info(f"ğŸ” ì „ì²´ ìº”ë“¤: {total}, ì´ìƒì¹˜: {anom} ({anom/total*100:.2f}%)")
