import os
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from sklearn.preprocessing import MinMaxScaler
from models.model import LSTMAutoencoder
from logs.log_config import setup_logger
from logs.shared_log import log_buffer

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ì„¤ì • ë° ì´ˆê¸°í™” â€”â€”â€”â€”â€”â€”â€”â€”â€”
setup_logger()
logging.info("ğŸ”„ ë°±í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")

# íŒŒë¼ë¯¸í„°
CSV_PATH      = "BTCUSDT_2025.csv"
SEQ_LEN       = 60
VOL_Z_THRESH  = 4.0       # ë¡œê·¸-z ì„ê³„ì¹˜
PRICE_RET_TH  = 0.005     # ì¢…ê°€ ë³€í™”ìœ¨ ì„ê³„ì¹˜
DEVICE        = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ëª¨ë¸ & ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) Autoencoder
model = LSTMAutoencoder(input_dim=5, seq_len=SEQ_LEN, hidden1=128, hidden2=64, latent=32)
model.load_state_dict(torch.load("models/best_lstm_autoencoder.pt", map_location=DEVICE))
model.to(DEVICE).eval()
logging.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# 2) MinMaxScaler íŒŒë¼ë¯¸í„°
min_vals, max_vals = np.load("models/minmax_scaler.npy", allow_pickle=True)
scaler = MinMaxScaler()
scaler.min_, scaler.scale_       = 0, 1/(max_vals - min_vals + 1e-8)
scaler.data_min_, scaler.data_max_ = min_vals, max_vals
logging.info("âœ… Scaler íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ")



# 3) IQR ì„ê³„ì¹˜
train_errors = np.load("models/train_recon_errors.npy")
q1, q3       = np.percentile(train_errors, [25, 75])
iqr          = q3 - q1
lower_thres  = q1 - 1.5 * iqr
upper_thres  = q3 + 1.5 * iqr
logging.info(f"âœ… IQR ì„ê³„ì¹˜: lower={lower_thres:.6f}, upper={upper_thres:.6f}")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” CSV ë¡œë“œ â€”â€”â€”â€”â€”â€”â€”â€”â€”
if not os.path.exists(CSV_PATH):
    CSV_PATH = os.path.join("data", CSV_PATH)
df = pd.read_csv(CSV_PATH, parse_dates=["timestamp"])
df.set_index("timestamp", inplace=True)
logging.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")

# â€”â€”â€”â€”â€”â€”â€”â€”â€” ì´ìƒì¹˜ íƒì§€ ë°±í…ŒìŠ¤íŠ¸ â€”â€”â€”â€”â€”â€”â€”â€”â€”
results = []
window = []

for ts, row in df.iterrows():
    candle = row[['open','high','low','close','volume']].values
    window.append(candle)

    if len(window) < SEQ_LEN + 1:
        results.append({
            'timestamp': ts,
            'close': row['close'],
            'mae': np.nan,
            'vol_z': np.nan,
            'price_ret': np.nan,
            'iqr_anomaly': False,
            'vol_price_anomaly': False,
            'anomaly': False
        })
        continue

    arr = np.array(window[-(SEQ_LEN+1):])
    # â€” ëª¨ë¸ ì¬êµ¬ì„± ì˜¤ì°¨
    diffed    = np.diff(arr, axis=0)[-SEQ_LEN:]
    scaled    = scaler.transform(diffed)
    x_tensor  = torch.tensor(scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        recon = model(x_tensor)
    mae = torch.mean(torch.abs(recon - x_tensor)).item()
    iqr_anom = (mae < lower_thres) or (mae > upper_thres)

    # â€” ë³¼ë¥¨+ê°€ê²© ìŠ¤íŒŒì´í¬
    vols      = arr[-SEQ_LEN:, 4]
    log_vols  = np.log1p(vols)
    mu, sigma = log_vols.mean(), log_vols.std(ddof=0)
    last_log  = np.log1p(arr[-1, 4])
    z_score   = (last_log - mu) / (sigma + 1e-8)

    prev_c    = arr[-2, 3]
    last_c    = arr[-1, 3]
    price_ret = (last_c - prev_c) / (prev_c + 1e-8)

    vol_spike    = abs(z_score) > VOL_Z_THRESH
    price_spike  = abs(price_ret) > PRICE_RET_TH
    vol_price_anom = vol_spike and price_spike

    final_anom = iqr_anom or vol_price_anom

    results.append({
        'timestamp': ts,
        'close': last_c,
        'mae': mae,
        'vol_z': z_score,
        'price_ret': price_ret,
        'iqr_anomaly': iqr_anom,
        'vol_price_anomaly': vol_price_anom,
        'anomaly': final_anom
    })

    window.pop(0)

# â€”â€”â€”â€”â€”â€”â€” DataFrame & ì‹œê°í™” â€”â€”â€”â€”â€”â€”â€”
res_df = pd.DataFrame(results).set_index('timestamp')

# IQR ê¸°ë°˜ ì´ìƒì¹˜ ê°œìˆ˜ ë¡œê¹…
iqr_count = int(res_df['iqr_anomaly'].sum())
logging.info(f"ğŸ” IQR ì´ìƒì¹˜ ê°œìˆ˜: {iqr_count}")

# ë³¼ë¥¨+ê°€ê²© ìŠ¤íŒŒì´í¬ ê°œìˆ˜ ë¡œê¹…
vol_count = int(res_df['vol_price_anomaly'].sum())
logging.info(f"ğŸ” ë³¼ë¥¨+ê°€ê²© ì´ìƒì¹˜ ê°œìˆ˜: {vol_count}")

# 1) IQR ê¸°ë°˜ ì´ìƒì¹˜ë§Œ
plt.figure(figsize=(12,6))
plt.plot(res_df.index, res_df['close'], alpha=0.6, label='Close')
mask_iqr = res_df['iqr_anomaly']
plt.scatter(
    res_df.index[mask_iqr],
    res_df['close'][mask_iqr],
    color='blue', s=10, marker='o',    # ì  í¬ê¸° 10ìœ¼ë¡œ ì¡°ì •
    label=f'IQR Anomaly ({iqr_count})'
)
plt.title("BTC 2025 â€” IQR ê¸°ë°˜ ì´ìƒì¹˜")
plt.xlabel("Time")
plt.ylabel("Close Price")
plt.legend()
plt.tight_layout()
plt.show()

# 2) ë³¼ë¥¨ìŠ¤íŒŒì´í¬ + ê°€ê²©ë³€ë™ ì´ìƒì¹˜ë§Œ
plt.figure(figsize=(12,6))
plt.plot(res_df.index, res_df['close'], alpha=0.6, label='Close')
mask_vol = res_df['vol_price_anomaly']
plt.scatter(
    res_df.index[mask_vol],
    res_df['close'][mask_vol],
    color='orange', s=10, marker='x',  # ì  í¬ê¸° 10ìœ¼ë¡œ ì¡°ì •
    label=f'Volume+Price Spike ({vol_count})'
)
plt.title("BTC 2025 â€” Volume Spike + Price Move ì´ìƒì¹˜")
plt.xlabel("Time")
plt.ylabel("Close Price")
plt.legend()
plt.tight_layout()
plt.show()


# â€”â€”â€”â€”â€”â€”â€” ê²°ê³¼ ìš”ì•½ â€”â€”â€”â€”â€”â€”â€”
total = len(res_df)
anom  = res_df['anomaly'].sum()
logging.info(f"ğŸ” ì „ì²´ ìº”ë“¤: {total}, ì´ìƒì¹˜: {anom} ({anom/total*100:.2f}%)")
