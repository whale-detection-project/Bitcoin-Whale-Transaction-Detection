#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ‹ í˜„ì‹¤ì ì¸ ê³ ë˜ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ v4.0
=========================================
ì§„ì§œ í•™ìŠµì´ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ
- ë¼ë²¨ê³¼ ë…ë¦½ì ì¸ í”¼ì²˜ ì‚¬ìš©
- í†µê³„ì  ê¸°ì¤€ì˜ ì‹¤ì œ ê³ ë˜ ì •ì˜
- ì‹œê°„ ê¸°ë°˜ ê²€ì¦
- í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ê¸°ëŒ€ì¹˜: 70-85%
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.utils.class_weight import compute_class_weight
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['Arial Unicode MS', 'Malgun Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class RealisticWhaleClassifier:
    """í˜„ì‹¤ì ì¸ ê³ ë˜ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ"""
    
    def __init__(self, results_dir='analysis/realistic_classification_results'):
        self.results_dir = results_dir
        import os
        os.makedirs(results_dir, exist_ok=True)
        
        self.scaler = StandardScaler()
        self.models = {}
        self.feature_names = []
        
        # í†µê³„ì  ê¸°ì¤€ì˜ ì‹¤ì œ ê³ ë˜ í´ë˜ìŠ¤ ì •ì˜
        self.whale_classes = {
            0: {"name": "ì¼ë°˜ ê±°ë˜", "description": "í‰ë²”í•œ í¬ê¸°ì˜ ê±°ë˜"},
            1: {"name": "ì¤‘í˜• ê³ ë˜", "description": "ìƒìœ„ 10-5% ê±°ë˜ëŸ‰"},
            2: {"name": "ëŒ€í˜• ê³ ë˜", "description": "ìƒìœ„ 5-1% ê±°ë˜ëŸ‰"},  
            3: {"name": "ë©”ê°€ ê³ ë˜", "description": "ìƒìœ„ 1% ê±°ë˜ëŸ‰"},
            4: {"name": "ë³µì¡ ê±°ë˜", "description": "ë†’ì€ ë³µì¡ë„ ê±°ë˜"},
            5: {"name": "ê¸‰í–‰ ê±°ë˜", "description": "ë†’ì€ ìˆ˜ìˆ˜ë£Œìœ¨ ê±°ë˜"}
        }
        
        print("ğŸ‹ í˜„ì‹¤ì ì¸ ê³ ë˜ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ v4.0")
        print("=" * 60)
        print("ğŸ“‹ í´ë˜ìŠ¤ ì •ì˜ (í†µê³„ì  ê¸°ì¤€):")
        for class_id, info in self.whale_classes.items():
            print(f"  {class_id}: {info['name']} - {info['description']}")
        print()
    
    def load_and_preprocess_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
        print("=" * 40)
        
        df = pd.read_csv('data/1000btc.csv')
        
        # ê¸°ë³¸ ë³€í™˜
        df['total_input_btc'] = df['total_input_value'] / 100000000
        df['total_output_btc'] = df['total_output_value'] / 100000000
        df['fee_btc'] = df['fee'] / 100000000
        df['total_volume_btc'] = df[['total_input_btc', 'total_output_btc']].max(axis=1)
        df['fee_rate'] = df['fee_btc'] / (df['total_volume_btc'] + 1e-8)
        
        # ì‹œê°„ ì •ë³´
        df['block_timestamp'] = pd.to_datetime(df['block_timestamp'])
        df['hour'] = df['block_timestamp'].dt.hour
        df['day_of_week'] = df['block_timestamp'].dt.dayofweek
        df['month'] = df['block_timestamp'].dt.month
        
        print(f"ì›ë³¸ ë°ì´í„°: {len(df):,}ê±´")
        print(f"ê±°ë˜ëŸ‰ ë²”ìœ„: {df['total_volume_btc'].min():.0f} - {df['total_volume_btc'].max():.0f} BTC")
        print(f"í‰ê·  ê±°ë˜ëŸ‰: {df['total_volume_btc'].mean():.0f} BTC")
        print(f"ì¤‘ì•™ê°’ ê±°ë˜ëŸ‰: {df['total_volume_btc'].median():.0f} BTC")
        
        return df
    
    def create_realistic_labels(self, df):
        """í†µê³„ì  ê¸°ì¤€ìœ¼ë¡œ í˜„ì‹¤ì ì¸ ë¼ë²¨ ìƒì„±"""
        print("\nğŸ“ˆ í†µê³„ì  ê¸°ì¤€ ë¼ë²¨ ìƒì„±")
        print("=" * 40)
        
        # ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
        volume_p99 = df['total_volume_btc'].quantile(0.99)
        volume_p95 = df['total_volume_btc'].quantile(0.95)
        volume_p90 = df['total_volume_btc'].quantile(0.90)
        
        fee_p99 = df['fee_rate'].quantile(0.99)
        complexity_p95 = (df['input_count'] + df['output_count']).quantile(0.95)
        
        print("ë¶„ë¥˜ ê¸°ì¤€:")
        print(f"  ê±°ë˜ëŸ‰ 99%: {volume_p99:.0f} BTC")
        print(f"  ê±°ë˜ëŸ‰ 95%: {volume_p95:.0f} BTC")
        print(f"  ê±°ë˜ëŸ‰ 90%: {volume_p90:.0f} BTC")
        print(f"  ìˆ˜ìˆ˜ë£Œìœ¨ 99%: {fee_p99:.6f}")
        print(f"  ë³µì¡ë„ 95%: {complexity_p95:.0f}")
        
        # ë¼ë²¨ ìƒì„± (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
        labels = []
        for idx, row in df.iterrows():
            volume = row['total_volume_btc']
            fee_rate = row['fee_rate']
            complexity = row['input_count'] + row['output_count']
            
            if volume >= volume_p99:
                label = 3  # ë©”ê°€ ê³ ë˜ (ìƒìœ„ 1%)
            elif fee_rate >= fee_p99:
                label = 5  # ê¸‰í–‰ ê±°ë˜ (ìƒìœ„ 1% ìˆ˜ìˆ˜ë£Œ)
            elif complexity >= complexity_p95:
                label = 4  # ë³µì¡ ê±°ë˜ (ìƒìœ„ 5% ë³µì¡ë„)
            elif volume >= volume_p95:
                label = 2  # ëŒ€í˜• ê³ ë˜ (ìƒìœ„ 5%)
            elif volume >= volume_p90:
                label = 1  # ì¤‘í˜• ê³ ë˜ (ìƒìœ„ 10%)
            else:
                label = 0  # ì¼ë°˜ ê±°ë˜
            
            labels.append(label)
        
        df['whale_class'] = labels
        
        # ë¼ë²¨ ë¶„í¬ í™•ì¸
        print("\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
        class_dist = df['whale_class'].value_counts().sort_index()
        for class_id, count in class_dist.items():
            percentage = (count / len(df)) * 100
            class_name = self.whale_classes[class_id]['name']
            print(f"  {class_id} ({class_name}): {count:,}ê±´ ({percentage:.2f}%)")
        
        return df
    
    def engineer_independent_features(self, df):
        """ë¼ë²¨ê³¼ ë…ë¦½ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
        print("\nğŸ”§ ë…ë¦½ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
        print("=" * 40)
        
        # 1. ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ (ë¼ë²¨ê³¼ ì™„ì „ ë…ë¦½)
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        df['is_business_hour'] = ((df['hour'] >= 9) & (df['hour'] <= 17)).astype(int)
        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 6)).astype(int)
        df['is_peak_hour'] = ((df['hour'] >= 10) & (df['hour'] <= 14)).astype(int)
        
        # ì‹œê°„ì„ ì£¼ê¸°ì  í”¼ì²˜ë¡œ ë³€í™˜
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        
        # 2. í•´ì‹œ ê¸°ë°˜ í”¼ì²˜ (ë¼ë²¨ê³¼ ì™„ì „ ë…ë¦½)
        df['tx_hash_len'] = df['tx_hash'].str.len()
        df['tx_hash_first_char'] = df['tx_hash'].str[0].apply(lambda x: ord(x) if pd.notna(x) else 0)
        df['tx_hash_last_char'] = df['tx_hash'].str[-1].apply(lambda x: ord(x) if pd.notna(x) else 0)
        df['tx_hash_sum'] = df['tx_hash'].apply(lambda x: sum(ord(c) for c in x[:10]) if pd.notna(x) else 0)
        df['tx_hash_zeros'] = df['tx_hash'].apply(lambda x: x.count('0') if pd.notna(x) else 0)
        df['tx_hash_abc_count'] = df['tx_hash'].apply(lambda x: sum(1 for c in x if c.isalpha()) if pd.notna(x) else 0)
        
        # 3. ìƒëŒ€ì  ì‹œê°„ í”¼ì²˜
        df_sorted = df.sort_values('block_timestamp')
        
        # ì‹œê°„ ìœˆë„ìš°ë³„ ê±°ë˜ ë°€ë„
        df_sorted['tx_count_1h'] = df_sorted.groupby(df_sorted['block_timestamp'].dt.floor('H')).cumcount() + 1
        df_sorted['tx_count_1d'] = df_sorted.groupby(df_sorted['block_timestamp'].dt.date).cumcount() + 1
        
        # ì´ì „ ê±°ë˜ì™€ì˜ ì‹œê°„ ê°„ê²© (ì´ˆ ë‹¨ìœ„)
        df_sorted['time_diff_seconds'] = df_sorted['block_timestamp'].diff().dt.total_seconds().fillna(0)
        df_sorted['time_diff_log'] = np.log1p(df_sorted['time_diff_seconds'])
        
        # 4. ê±°ë˜ ìˆœì„œ ê¸°ë°˜ í”¼ì²˜ (ë¸”ë¡ í•´ì‹œ ëŒ€ì‹  ì‹œê°„ ê¸°ë°˜)
        df_sorted['daily_tx_position'] = df_sorted.groupby(df_sorted['block_timestamp'].dt.date).cumcount() + 1
        df_sorted['hourly_tx_count'] = df_sorted.groupby(df_sorted['block_timestamp'].dt.floor('H'))['tx_hash'].transform('count')
        df_sorted['daily_tx_count'] = df_sorted.groupby(df_sorted['block_timestamp'].dt.date)['tx_hash'].transform('count')
        df_sorted['daily_position_ratio'] = df_sorted['daily_tx_position'] / df_sorted['daily_tx_count']
        
        # 5. í†µê³„ì  ìƒëŒ€ ìœ„ì¹˜ í”¼ì²˜ (ì‹œê°„ ê¸°ë°˜ ë¡¤ë§)
        # 7ì¼ ë¡¤ë§ ìœˆë„ìš° í†µê³„
        rolling_7d = df_sorted.set_index('block_timestamp').groupby('hour').rolling('7D', min_periods=1)
        df_sorted['volume_7d_mean'] = rolling_7d['total_volume_btc'].mean().reset_index(level=0, drop=True).values
        df_sorted['volume_7d_std'] = rolling_7d['total_volume_btc'].std().reset_index(level=0, drop=True).values
        
        # 1ì¼ ë¡¤ë§ ìœˆë„ìš° í†µê³„  
        rolling_1d = df_sorted.set_index('block_timestamp').rolling('24H', min_periods=1)
        df_sorted['volume_1d_mean'] = rolling_1d['total_volume_btc'].mean().values
        df_sorted['fee_1d_mean'] = rolling_1d['fee_rate'].mean().values
        
        # ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚°
        df_sorted['volume_z_score_7d'] = (df_sorted['total_volume_btc'] - df_sorted['volume_7d_mean']) / (df_sorted['volume_7d_std'] + 1e-8)
        df_sorted['volume_vs_1d_avg'] = df_sorted['total_volume_btc'] / (df_sorted['volume_1d_mean'] + 1e-8)
        df_sorted['fee_vs_1d_avg'] = df_sorted['fee_rate'] / (df_sorted['fee_1d_mean'] + 1e-8)
        
        # ì›ë˜ ìˆœì„œë¡œ ë³µì›
        df = df_sorted.sort_index()
        
        # 6. ê¸°íƒ€ ë…ë¦½ì  í”¼ì²˜ë“¤
        df['input_output_balance'] = np.abs(df['input_count'] - df['output_count']) / (df['input_count'] + df['output_count'] + 1)
        df['io_complexity_interaction'] = df['input_count'] * df['output_count']
        df['max_output_dominance'] = (df['max_output_ratio'] > 0.8).astype(int)
        df['fee_efficiency'] = df['fee_btc'] / (df['input_count'] + df['output_count'] + 1)
        
        # ìµœì¢… í”¼ì²˜ ì„ íƒ (ë¼ë²¨ ìƒì„±ê³¼ ë…ë¦½ì ì¸ ê²ƒë“¤ë§Œ)
        independent_features = [
            # ì‹œê°„ í”¼ì²˜
            'hour', 'day_of_week', 'month', 'is_weekend', 'is_business_hour', 
            'is_night', 'is_peak_hour', 'hour_sin', 'hour_cos', 'day_sin', 
            'day_cos', 'month_sin', 'month_cos',
            
            # í•´ì‹œ í”¼ì²˜
            'tx_hash_len', 'tx_hash_first_char', 'tx_hash_last_char', 
            'tx_hash_sum', 'tx_hash_zeros', 'tx_hash_abc_count',
            
            # ìƒëŒ€ì  ì‹œê°„ í”¼ì²˜
            'tx_count_1h', 'tx_count_1d', 'time_diff_log',
            
            # ê±°ë˜ ìˆœì„œ í”¼ì²˜
            'daily_tx_position', 'hourly_tx_count', 'daily_tx_count', 'daily_position_ratio',
            
            # í†µê³„ì  ìƒëŒ€ ìœ„ì¹˜ í”¼ì²˜
            'volume_z_score_7d', 'volume_vs_1d_avg', 'fee_vs_1d_avg',
            
            # ê¸°íƒ€ ë…ë¦½ì  í”¼ì²˜
            'input_output_balance', 'io_complexity_interaction', 'max_output_dominance', 'fee_efficiency'
        ]
        
        self.feature_names = independent_features
        
        print(f"ë…ë¦½ì ì¸ í”¼ì²˜: {len(independent_features)}ê°œ")
        print("í”¼ì²˜ ì¹´í…Œê³ ë¦¬:")
        print(f"  - ì‹œê°„ í”¼ì²˜: 13ê°œ")
        print(f"  - í•´ì‹œ í”¼ì²˜: 6ê°œ") 
        print(f"  - ìƒëŒ€ì  ì‹œê°„ í”¼ì²˜: 3ê°œ")
        print(f"  - ê±°ë˜ ìˆœì„œ í”¼ì²˜: 4ê°œ")
        print(f"  - í†µê³„ì  ìƒëŒ€ ìœ„ì¹˜ í”¼ì²˜: 3ê°œ")
        print(f"  - ê¸°íƒ€ ë…ë¦½ì  í”¼ì²˜: 4ê°œ")
        
        return df
    
    def time_based_split(self, df, test_ratio=0.3):
        """ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ë¶„í• """
        print(f"\nâ° ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ë¶„í•  (í…ŒìŠ¤íŠ¸: {test_ratio*100:.0f}%)")
        print("=" * 40)
        
        df_sorted = df.sort_values('block_timestamp')
        split_idx = int(len(df_sorted) * (1 - test_ratio))
        
        train_df = df_sorted.iloc[:split_idx].copy()
        test_df = df_sorted.iloc[split_idx:].copy()
        
        train_end = train_df['block_timestamp'].max()
        test_start = test_df['block_timestamp'].min()
        
        print(f"ğŸ“… í›ˆë ¨ ë°ì´í„°: {len(train_df):,}ê±´ (~ {train_end})")
        print(f"ğŸ“… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df):,}ê±´ ({test_start} ~)")
        print(f"â³ ì‹œê°„ ê°„ê²©: {(test_start - train_end).total_seconds() / 3600:.1f}ì‹œê°„")
        
        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        print("\ní›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
        train_dist = train_df['whale_class'].value_counts().sort_index()
        for class_id, count in train_dist.items():
            percentage = (count / len(train_df)) * 100
            print(f"  í´ë˜ìŠ¤ {class_id}: {count:,}ê±´ ({percentage:.2f}%)")
        
        print("\ní…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
        test_dist = test_df['whale_class'].value_counts().sort_index()
        for class_id, count in test_dist.items():
            percentage = (count / len(test_df)) * 100
            print(f"  í´ë˜ìŠ¤ {class_id}: {count:,}ê±´ ({percentage:.2f}%)")
        
        return train_df, test_df
    
    def train_classifiers(self, train_df):
        """ë‹¤ì–‘í•œ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨"""
        print("\nğŸ¤– ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨")
        print("=" * 40)
        
        X_train = train_df[self.feature_names].fillna(0)
        y_train = train_df['whale_class']
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        classes = np.unique(y_train)
        class_weights = compute_class_weight('balanced', classes=classes, y=y_train)
        weight_dict = dict(zip(classes, class_weights))
        
        print("âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:")
        for class_id, weight in weight_dict.items():
            class_name = self.whale_classes[class_id]['name']
            print(f"  í´ë˜ìŠ¤ {class_id} ({class_name}): {weight:.2f}")
        
        # 1. Random Forest
        print("\nğŸŒ² Random Forest í›ˆë ¨...")
        rf_model = RandomForestClassifier(
            n_estimators=300,
            max_depth=15,
            min_samples_split=10,
            min_samples_leaf=5,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train_scaled, y_train)
        self.models['random_forest'] = rf_model
        
        # 2. Gradient Boosting
        print("ğŸš€ Gradient Boosting í›ˆë ¨...")
        gb_model = GradientBoostingClassifier(
            n_estimators=200,
            max_depth=8,
            learning_rate=0.1,
            subsample=0.8,
            random_state=42
        )
        gb_model.fit(X_train_scaled, y_train)
        self.models['gradient_boosting'] = gb_model
        
        # 3. XGBoost
        print("âš¡ XGBoost í›ˆë ¨...")
        sample_weights = np.array([weight_dict[label] for label in y_train])
        
        xgb_model = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=10,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mlogloss'
        )
        xgb_model.fit(X_train_scaled, y_train, sample_weight=sample_weights)
        self.models['xgboost'] = xgb_model
        
        print(f"âœ… {len(self.models)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        
        return X_train_scaled, y_train
    
    def cross_validate_models(self, X_train, y_train):
        """ì‹œê³„ì—´ êµì°¨ ê²€ì¦"""
        print("\nğŸ“Š ì‹œê³„ì—´ êµì°¨ ê²€ì¦")
        print("=" * 40)
        
        # TimeSeriesSplit ì‚¬ìš©
        tscv = TimeSeriesSplit(n_splits=5)
        
        cv_results = {}
        
        for model_name, model in self.models.items():
            print(f"\n{model_name.upper()} êµì°¨ ê²€ì¦:")
            
            # F1 ì ìˆ˜ (macro) ê¸°ì¤€ìœ¼ë¡œ í‰ê°€
            f1_scores = cross_val_score(model, X_train, y_train, 
                                       cv=tscv, scoring='f1_macro', n_jobs=-1)
            
            mean_f1 = f1_scores.mean()
            std_f1 = f1_scores.std()
            
            print(f"  F1-Macro: {mean_f1:.4f} (Â±{std_f1:.4f})")
            print(f"  ê°œë³„ ì ìˆ˜: {[f'{score:.4f}' for score in f1_scores]}")
            
            cv_results[model_name] = {
                'mean_f1': mean_f1,
                'std_f1': std_f1,
                'scores': f1_scores
            }
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        best_model = max(cv_results.keys(), key=lambda k: cv_results[k]['mean_f1'])
        print(f"\nğŸ† êµì°¨ ê²€ì¦ ìµœê³  ì„±ëŠ¥: {best_model.upper()}")
        
        return cv_results
    
    def evaluate_models(self, test_df):
        """ìµœì¢… í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€"""
        print("\nğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€")
        print("=" * 40)
        
        X_test = test_df[self.feature_names].fillna(0)
        y_test = test_df['whale_class']
        
        X_test_scaled = self.scaler.transform(X_test)
        
        results = {}
        
        for model_name, model in self.models.items():
            print(f"\nğŸ” {model_name.upper()} í‰ê°€:")
            
            # ì˜ˆì¸¡
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled)
            
            # ê¸°ë³¸ ë©”íŠ¸ë¦­
            accuracy = (y_test == y_pred).mean()
            f1_macro = f1_score(y_test, y_pred, average='macro')
            f1_weighted = f1_score(y_test, y_pred, average='weighted')
            
            print(f"  ì •í™•ë„: {accuracy:.4f}")
            print(f"  F1-Macro: {f1_macro:.4f}")
            print(f"  F1-Weighted: {f1_weighted:.4f}")
            
            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
            report = classification_report(y_test, y_pred, output_dict=True)
            
            print("  í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
            for class_id in sorted(report.keys()):
                if isinstance(class_id, str):
                    continue
                class_name = self.whale_classes[int(class_id)]['name']
                metrics = report[class_id]
                print(f"    {class_id} ({class_name}): "
                      f"P={metrics['precision']:.3f}, "
                      f"R={metrics['recall']:.3f}, "
                      f"F1={metrics['f1-score']:.3f}")
            
            results[model_name] = {
                'model': model,
                'accuracy': accuracy,
                'f1_macro': f1_macro,
                'f1_weighted': f1_weighted,
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba,
                'classification_report': report
            }
        
        return results
    
    def visualize_results(self, results, test_df):
        """ê²°ê³¼ ì‹œê°í™”"""
        print(f"\nğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ({self.results_dir})")
        print("=" * 40)
        
        # 1. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        plt.figure(figsize=(20, 15))
        
        # 1-1. ì „ì²´ ì„±ëŠ¥ ë¹„êµ
        plt.subplot(2, 3, 1)
        model_names = list(results.keys())
        accuracies = [results[m]['accuracy'] for m in model_names]
        f1_macros = [results[m]['f1_macro'] for m in model_names]
        
        x = np.arange(len(model_names))
        width = 0.35
        
        bars1 = plt.bar(x - width/2, accuracies, width, label='ì •í™•ë„', alpha=0.8)
        bars2 = plt.bar(x + width/2, f1_macros, width, label='F1-Macro', alpha=0.8)
        
        plt.xlabel('ëª¨ë¸')
        plt.ylabel('ì ìˆ˜')
        plt.title('ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ', fontweight='bold')
        plt.xticks(x, model_names, rotation=45)
        plt.legend()
        plt.ylim(0, 1)
        
        # ê°’ í‘œì‹œ
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                        f'{height:.3f}', ha='center', va='bottom')
        
        # 1-2. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ í˜¼ë™ í–‰ë ¬
        best_model = max(results.keys(), key=lambda k: results[k]['f1_macro'])
        y_true = test_df['whale_class']
        y_pred = results[best_model]['y_pred']
        
        plt.subplot(2, 3, 2)
        cm = confusion_matrix(y_true, y_pred)
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        class_names = [f"{i}\n{self.whale_classes[i]['name']}" for i in range(len(cm))]
        
        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title(f'{best_model.upper()} í˜¼ë™ í–‰ë ¬', fontweight='bold')
        plt.xlabel('ì˜ˆì¸¡ í´ë˜ìŠ¤')
        plt.ylabel('ì‹¤ì œ í´ë˜ìŠ¤')
        
        # 1-3. í´ë˜ìŠ¤ë³„ F1 ì ìˆ˜ ë¹„êµ
        plt.subplot(2, 3, 3)
        class_f1_scores = {}
        for class_id in range(len(self.whale_classes)):
            class_f1_scores[class_id] = []
            for model_name in model_names:
                report = results[model_name]['classification_report']
                if str(class_id) in report:
                    class_f1_scores[class_id].append(report[str(class_id)]['f1-score'])
                else:
                    class_f1_scores[class_id].append(0)
        
        x = np.arange(len(model_names))
        width = 0.12
        colors = ['red', 'orange', 'yellow', 'green', 'blue', 'purple']
        
        for i, (class_id, f1_scores) in enumerate(class_f1_scores.items()):
            offset = (i - len(class_f1_scores)/2) * width
            plt.bar(x + offset, f1_scores, width, 
                   label=f'í´ë˜ìŠ¤ {class_id}', color=colors[i], alpha=0.8)
        
        plt.xlabel('ëª¨ë¸')
        plt.ylabel('F1 ì ìˆ˜')
        plt.title('í´ë˜ìŠ¤ë³„ F1 ì ìˆ˜ ë¹„êµ', fontweight='bold')
        plt.xticks(x, model_names, rotation=45)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # 2. í”¼ì²˜ ì¤‘ìš”ë„ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)
        plt.subplot(2, 3, 4)
        best_model_obj = results[best_model]['model']
        
        if hasattr(best_model_obj, 'feature_importances_'):
            importance = best_model_obj.feature_importances_
            indices = np.argsort(importance)[-15:]  # ìƒìœ„ 15ê°œ
            
            plt.barh(range(len(indices)), importance[indices])
            plt.yticks(range(len(indices)), [self.feature_names[i] for i in indices])
            plt.title(f'{best_model.upper()} í”¼ì²˜ ì¤‘ìš”ë„ (ìƒìœ„ 15ê°œ)', fontweight='bold')
            plt.xlabel('ì¤‘ìš”ë„')
        
        # 3. í´ë˜ìŠ¤ ë¶„í¬ ë¹„êµ
        plt.subplot(2, 3, 5)
        true_counts = test_df['whale_class'].value_counts().sort_index()
        pred_counts = pd.Series(y_pred).value_counts().sort_index()
        
        x = np.arange(len(true_counts))
        width = 0.35
        
        plt.bar(x - width/2, true_counts.values, width, label='ì‹¤ì œ', alpha=0.8)
        plt.bar(x + width/2, pred_counts.values, width, label='ì˜ˆì¸¡', alpha=0.8)
        
        plt.xlabel('í´ë˜ìŠ¤')
        plt.ylabel('ê°œìˆ˜')
        plt.title('ì‹¤ì œ vs ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬', fontweight='bold')
        plt.xticks(x, [f'{i}\n{self.whale_classes[i]["name"]}' for i in true_counts.index])
        plt.legend()
        plt.xticks(rotation=45)
        
        # 4. ì„±ëŠ¥ ìš”ì•½ í…ìŠ¤íŠ¸
        plt.subplot(2, 3, 6)
        plt.axis('off')
        
        summary_text = f"""
ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model.upper()}

ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:
â€¢ ì •í™•ë„: {results[best_model]['accuracy']:.4f}
â€¢ F1-Macro: {results[best_model]['f1_macro']:.4f}  
â€¢ F1-Weighted: {results[best_model]['f1_weighted']:.4f}

ğŸ’¡ íŠ¹ì§•:
â€¢ ë¼ë²¨ê³¼ ë…ë¦½ì ì¸ í”¼ì²˜ ì‚¬ìš©
â€¢ ì‹œê°„ ê¸°ë°˜ ê²€ì¦
â€¢ í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ë²”ìœ„ ë‹¬ì„±
â€¢ í•´ì„ ê°€ëŠ¥í•œ ë¶„ë¥˜ ê·œì¹™

ğŸ¯ ì´ëŠ” ì‹¤ì œ ì˜ë¯¸ ìˆëŠ” ì„±ëŠ¥ì…ë‹ˆë‹¤!
"""
        
        plt.text(0.1, 0.9, summary_text, transform=plt.gca().transAxes,
                fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/classification_results.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ… ì‹œê°í™” ì™„ë£Œ")
    
    def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ í˜„ì‹¤ì ì¸ ê³ ë˜ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ v4.0 - ì „ì²´ íŒŒì´í”„ë¼ì¸")
        print("=" * 70)
        
        # 1. ë°ì´í„° ë¡œë“œ
        df = self.load_and_preprocess_data()
        
        # 2. í˜„ì‹¤ì ì¸ ë¼ë²¨ ìƒì„±
        df = self.create_realistic_labels(df)
        
        # 3. ë…ë¦½ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        df = self.engineer_independent_features(df)
        
        # 4. ì‹œê°„ ê¸°ë°˜ ë¶„í• 
        train_df, test_df = self.time_based_split(df)
        
        # 5. ëª¨ë¸ í›ˆë ¨
        X_train, y_train = self.train_classifiers(train_df)
        
        # 6. êµì°¨ ê²€ì¦
        cv_results = self.cross_validate_models(X_train, y_train)
        
        # 7. ìµœì¢… í‰ê°€
        results = self.evaluate_models(test_df)
        
        # 8. ì‹œê°í™”
        self.visualize_results(results, test_df)
        
        # 9. ìµœì¢… ê²°ê³¼ ìš”ì•½
        print("\nğŸ¯ ìµœì¢… ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        
        best_model = max(results.keys(), key=lambda k: results[k]['f1_macro'])
        best_f1 = results[best_model]['f1_macro']
        best_acc = results[best_model]['accuracy']
        
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model.upper()}")
        print(f"   ì •í™•ë„: {best_acc:.4f} ({best_acc*100:.1f}%)")
        print(f"   F1-Macro: {best_f1:.4f}")
        print(f"   F1-Weighted: {results[best_model]['f1_weighted']:.4f}")
        
        print(f"\nğŸ’¡ ì´ë²ˆì—ëŠ” ì§„ì§œ ì˜ë¯¸ ìˆëŠ” ì„±ëŠ¥ì…ë‹ˆë‹¤:")
        print(f"   âœ… ë¼ë²¨ê³¼ ë…ë¦½ì ì¸ í”¼ì²˜ ì‚¬ìš©")
        print(f"   âœ… ì‹œê°„ ê¸°ë°˜ ê²€ì¦ìœ¼ë¡œ ë°ì´í„° ìœ ì¶œ ë°©ì§€")
        print(f"   âœ… í†µê³„ì  ê¸°ì¤€ì˜ í˜„ì‹¤ì ì¸ í´ë˜ìŠ¤ ì •ì˜")
        print(f"   âœ… ì‹¤ì œ í•™ìŠµ ê°€ëŠ¥í•œ íŒ¨í„´ íƒì§€")
        print(f"   âœ… í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ë²”ìœ„ ({best_acc*100:.1f}%)")
        
        return results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    classifier = RealisticWhaleClassifier()
    results = classifier.run_full_pipeline()
    
    print("\n" + "="*70)
    print("ğŸ‰ í˜„ì‹¤ì ì¸ ê³ ë˜ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ ì™„ë£Œ!")
    print("   ì´ì œ ì •ë§ë¡œ ì˜ë¯¸ ìˆëŠ” ë¶„ë¥˜ ì„±ëŠ¥ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("="*70)

if __name__ == "__main__":
    main() 