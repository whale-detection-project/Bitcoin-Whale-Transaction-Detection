#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ‹ ê³ ë˜ ê±°ë˜ íƒì§€ ì‹œìŠ¤í…œ v2.0 - ì™„ì „ ì¬ì„¤ê³„
==============================================
ì‹¤ì œ ë„ë©”ì¸ ì§€ì‹ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ
í˜„ì‹¤ì ì¸ ê³ ë˜ ê±°ë˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ

í•µì‹¬ ì›ì¹™:
1. ë„ë©”ì¸ ì „ë¬¸ê°€ ì§€ì‹ ê¸°ë°˜ ê·œì¹™
2. ì‹œê°„ ê¸°ë°˜ ê²€ì¦ (ê³¼ê±°â†’ë¯¸ë˜)
3. í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ê¸°ëŒ€ì¹˜
4. í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['AppleGothic', 'Malgun Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class WhaleDetectorV2:
    def __init__(self, results_dir='analysis/whale_v2_results'):
        self.results_dir = results_dir
        import os
        os.makedirs(results_dir, exist_ok=True)
        
        # ì‹¤ì œ ê³ ë˜ ë¶„ë¥˜ ê¸°ì¤€ (ë„ë©”ì¸ ì „ë¬¸ê°€ ì§€ì‹ ê¸°ë°˜)
        self.whale_definitions = {
            'mega_whale': {
                'name': 'ë©”ê°€ ê³ ë˜',
                'description': 'ì´ˆëŒ€í˜• ê±°ë˜ (10,000+ BTC)',
                'min_volume': 10000,
                'characteristics': 'ì‹œì¥ ì˜í–¥ë ¥ ê·¹ëŒ€'
            },
            'giant_whale': {
                'name': 'ê±°ëŒ€ ê³ ë˜', 
                'description': 'ëŒ€í˜• ê±°ë˜ (5,000-10,000 BTC)',
                'min_volume': 5000,
                'max_volume': 10000,
                'characteristics': 'ê¸°ê´€ íˆ¬ììê¸‰'
            },
            'large_whale': {
                'name': 'ëŒ€í˜• ê³ ë˜',
                'description': 'ì¤‘ëŒ€í˜• ê±°ë˜ (2,000-5,000 BTC)',
                'min_volume': 2000,
                'max_volume': 5000,
                'characteristics': 'ë¶€ìœ í•œ ê°œì¸/ì†Œê·œëª¨ ê¸°ê´€'
            },
            'collector_whale': {
                'name': 'ìˆ˜ì§‘í˜• ê³ ë˜',
                'description': 'ë‹¤ìˆ˜ ì…ë ¥, ì†Œìˆ˜ ì¶œë ¥ (ì§‘ì¤‘)',
                'min_inputs': 10,
                'max_outputs': 3,
                'min_volume': 1000,
                'characteristics': 'ìê¸ˆ ì§‘ì¤‘/í†µí•©'
            },
            'distributor_whale': {
                'name': 'ë¶„ì‚°í˜• ê³ ë˜',
                'description': 'ì†Œìˆ˜ ì…ë ¥, ë‹¤ìˆ˜ ì¶œë ¥ (ë¶„ì‚°)',
                'max_inputs': 3,
                'min_outputs': 10,
                'min_volume': 1000,
                'characteristics': 'ìê¸ˆ ë¶„ì‚°/ë°°í¬'
            },
            'express_whale': {
                'name': 'ê¸‰í–‰ ê³ ë˜',
                'description': 'ê³ ìˆ˜ìˆ˜ë£Œ ê±°ë˜ (ê¸´ê¸‰ì„±)',
                'min_fee_rate': 0.001,  # 0.1%
                'min_volume': 1000,
                'characteristics': 'ì‹œê¸‰í•œ ê±°ë˜'
            },
            'normal_large': {
                'name': 'ì¼ë°˜ ëŒ€í˜•',
                'description': 'ê¸°íƒ€ 1000+ BTC ê±°ë˜',
                'min_volume': 1000,
                'characteristics': 'ì¼ë°˜ì ì¸ ëŒ€í˜• ê±°ë˜'
            }
        }
        
        print("ğŸ‹ ê³ ë˜ ê±°ë˜ íƒì§€ ì‹œìŠ¤í…œ v2.0 ì´ˆê¸°í™”")
        print("=" * 50)
        print("ğŸ“‹ ê³ ë˜ ë¶„ë¥˜ ê¸°ì¤€:")
        for whale_type, info in self.whale_definitions.items():
            print(f"  {info['name']}: {info['description']}")
        print()
    
    def load_and_prepare_data(self, data_path='data/1000btc.csv'):
        """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬...")
        
        df = pd.read_csv(data_path)
        print(f"âœ… ì›ë³¸ ë°ì´í„°: {len(df):,}ê±´")
        
        # BTC ë‹¨ìœ„ ë³€í™˜
        df['total_input_btc'] = df['total_input_value'] / 100000000
        df['total_output_btc'] = df['total_output_value'] / 100000000
        df['fee_btc'] = df['fee'] / 100000000
        df['max_output_btc'] = df['max_output_value'] / 100000000
        df['total_volume_btc'] = df[['total_input_btc', 'total_output_btc']].max(axis=1)
        
        # ì‹œê°„ ì •ë³´ ì¶”ê°€
        df['block_timestamp'] = pd.to_datetime(df['block_timestamp'])
        df['date'] = df['block_timestamp'].dt.date
        df['hour'] = df['block_timestamp'].dt.hour
        df['day_of_week'] = df['block_timestamp'].dt.dayofweek
        
        # ìˆ˜ìˆ˜ë£Œìœ¨ ê³„ì‚°
        df['fee_rate'] = df['fee_btc'] / (df['total_volume_btc'] + 1e-8)
        
        # ê¸°ë³¸ í†µê³„
        print(f"ğŸ“ˆ ê±°ë˜ëŸ‰ ë²”ìœ„: {df['total_volume_btc'].min():.0f} - {df['total_volume_btc'].max():,.0f} BTC")
        print(f"ğŸ“ˆ í‰ê·  ê±°ë˜ëŸ‰: {df['total_volume_btc'].mean():,.0f} BTC")
        print(f"ğŸ“ˆ ìˆ˜ìˆ˜ë£Œìœ¨ ë²”ìœ„: {df['fee_rate'].min():.6f} - {df['fee_rate'].max():.6f}")
        print()
        
        return df
    
    def create_domain_based_labels(self, df):
        """ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë¼ë²¨ ìƒì„±"""
        print("ğŸ§  ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë¼ë²¨ ìƒì„±...")
        
        labels = []
        label_names = []
        
        for idx, row in df.iterrows():
            volume = row['total_volume_btc']
            inputs = row['input_count']
            outputs = row['output_count']
            fee_rate = row['fee_rate']
            concentration = row['max_output_ratio']
            
            # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¶„ë¥˜ (ìƒìœ„ ì¡°ê±´ë¶€í„° ì²´í¬)
            if volume >= 10000:
                label = 0  # ë©”ê°€ ê³ ë˜
                label_name = 'mega_whale'
            elif volume >= 5000:
                label = 1  # ê±°ëŒ€ ê³ ë˜
                label_name = 'giant_whale'
            elif volume >= 2000:
                label = 2  # ëŒ€í˜• ê³ ë˜
                label_name = 'large_whale'
            elif inputs >= 10 and outputs <= 3 and volume >= 1000:
                label = 3  # ìˆ˜ì§‘í˜• ê³ ë˜
                label_name = 'collector_whale'
            elif inputs <= 3 and outputs >= 10 and volume >= 1000:
                label = 4  # ë¶„ì‚°í˜• ê³ ë˜
                label_name = 'distributor_whale'
            elif fee_rate >= 0.001 and volume >= 1000:
                label = 5  # ê¸‰í–‰ ê³ ë˜
                label_name = 'express_whale'
            else:
                label = 6  # ì¼ë°˜ ëŒ€í˜•
                label_name = 'normal_large'
            
            labels.append(label)
            label_names.append(label_name)
        
        df['whale_label'] = labels
        df['whale_type'] = label_names
        
        # ë¼ë²¨ ë¶„í¬ í™•ì¸
        print("ğŸ“Š ë¼ë²¨ ë¶„í¬:")
        label_dist = df['whale_label'].value_counts().sort_index()
        for label_id, count in label_dist.items():
            whale_type = df[df['whale_label'] == label_id]['whale_type'].iloc[0]
            whale_name = self.whale_definitions[whale_type]['name']
            percentage = (count / len(df)) * 100
            print(f"  {label_id} ({whale_name}): {count:,}ê±´ ({percentage:.1f}%)")
        
        print()
        return df
    
    def engineer_features(self, df):
        """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ë¼ë²¨ê³¼ ë…ë¦½ì ì¸ í”¼ì²˜ë“¤)"""
        print("ğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§...")
        
        # 1. ë¹„ìœ¨ í”¼ì²˜ë“¤
        df['input_output_ratio'] = df['input_count'] / (df['output_count'] + 1)
        df['output_input_ratio'] = df['output_count'] / (df['input_count'] + 1)
        df['complexity_score'] = df['input_count'] + df['output_count']
        
        # 2. ë¡œê·¸ ë³€í™˜ í”¼ì²˜ë“¤ (ìŠ¤ì¼€ì¼ ì •ê·œí™”)
        df['volume_log'] = np.log1p(df['total_volume_btc'])
        df['fee_log'] = np.log1p(df['fee_btc'])
        df['input_log'] = np.log1p(df['input_count'])
        df['output_log'] = np.log1p(df['output_count'])
        
        # 3. ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ë“¤
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        df['is_business_hour'] = ((df['hour'] >= 9) & (df['hour'] <= 17)).astype(int)
        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 6)).astype(int)
        
        # 4. ìƒëŒ€ì  í¬ê¸° í”¼ì²˜ë“¤ (ì‹œê°„ ìœˆë„ìš° ê¸°ë°˜)
        df = df.sort_values('block_timestamp')
        
        # 7ì¼ ì´ë™ í‰ê·  ëŒ€ë¹„ í¬ê¸°
        df['volume_vs_7d_avg'] = df['total_volume_btc'] / (
            df['total_volume_btc'].rolling(window=7*24*6, min_periods=1).mean() + 1e-8
        )
        
        # 1ì¼ ì´ë™ í‰ê·  ëŒ€ë¹„ í¬ê¸°  
        df['volume_vs_1d_avg'] = df['total_volume_btc'] / (
            df['total_volume_btc'].rolling(window=24*6, min_periods=1).mean() + 1e-8
        )
        
        # 5. ì§‘ì¤‘ë„ ê´€ë ¨ í”¼ì²˜ë“¤
        df['concentration_tier'] = pd.cut(
            df['max_output_ratio'], 
            bins=[0, 0.5, 0.8, 0.95, 1.0], 
            labels=[0, 1, 2, 3]
        ).astype(float)
        
        # 6. ìˆ˜ìˆ˜ë£Œ ê´€ë ¨ í”¼ì²˜ë“¤
        df['fee_percentile'] = df['fee_rate'].rank(pct=True)
        df['is_high_fee'] = (df['fee_rate'] > df['fee_rate'].quantile(0.9)).astype(int)
        
        # ëª¨ë¸ë§ìš© í”¼ì²˜ ì„ íƒ (ë¼ë²¨ ìƒì„±ì— ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì€ í”¼ì²˜ë“¤)
        feature_cols = [
            # ë¹„ìœ¨ í”¼ì²˜
            'input_output_ratio', 'output_input_ratio', 'complexity_score',
            
            # ë¡œê·¸ í”¼ì²˜  
            'volume_log', 'fee_log', 'input_log', 'output_log',
            
            # ì‹œê°„ í”¼ì²˜
            'hour', 'day_of_week', 'is_weekend', 'is_business_hour', 'is_night',
            
            # ìƒëŒ€ì  í¬ê¸° í”¼ì²˜
            'volume_vs_7d_avg', 'volume_vs_1d_avg',
            
            # ì§‘ì¤‘ë„ í”¼ì²˜
            'concentration_tier',
            
            # ìˆ˜ìˆ˜ë£Œ í”¼ì²˜
            'fee_percentile', 'is_high_fee'
        ]
        
        print(f"âœ… ìƒì„±ëœ í”¼ì²˜: {len(feature_cols)}ê°œ")
        print(f"ğŸ“‹ í”¼ì²˜ ëª©ë¡: {feature_cols}")
        print()
        
        return df, feature_cols
    
    def time_based_split(self, df, test_ratio=0.3):
        """ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ë¶„í•  (ê³¼ê±° â†’ ë¯¸ë˜)"""
        print("â° ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ë¶„í• ...")
        
        df_sorted = df.sort_values('block_timestamp')
        split_idx = int(len(df_sorted) * (1 - test_ratio))
        
        train_df = df_sorted.iloc[:split_idx].copy()
        test_df = df_sorted.iloc[split_idx:].copy()
        
        train_end = train_df['block_timestamp'].max()
        test_start = test_df['block_timestamp'].min()
        
        print(f"ğŸ“… í›ˆë ¨ ë°ì´í„°: {len(train_df):,}ê±´ (~ {train_end})")
        print(f"ğŸ“… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df):,}ê±´ ({test_start} ~)")
        print(f"â³ ì‹œê°„ ê°„ê²©: {(test_start - train_end).days}ì¼")
        print()
        
        return train_df, test_df
    
    def train_models(self, train_df, feature_cols):
        """ì—¬ëŸ¬ ëª¨ë¸ í›ˆë ¨ ë° ë¹„êµ"""
        print("ğŸ¤– ëª¨ë¸ í›ˆë ¨...")
        
        X_train = train_df[feature_cols].fillna(0)
        y_train = train_df['whale_label']
        
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        from sklearn.utils.class_weight import compute_class_weight
        classes = np.unique(y_train)
        class_weights = compute_class_weight('balanced', classes=classes, y=y_train)
        weight_dict = dict(zip(classes, class_weights))
        
        print("âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:")
        for class_id, weight in weight_dict.items():
            whale_type = train_df[train_df['whale_label'] == class_id]['whale_type'].iloc[0]
            whale_name = self.whale_definitions[whale_type]['name']
            print(f"  {class_id} ({whale_name}): {weight:.2f}")
        print()
        
        models = {}
        
        # 1. Random Forest
        print("ğŸŒ² Random Forest í›ˆë ¨...")
        rf_model = RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train, y_train)
        models['random_forest'] = rf_model
        
        # 2. XGBoost
        print("ğŸš€ XGBoost í›ˆë ¨...")
        sample_weights = np.array([weight_dict[label] for label in y_train])
        
        xgb_model = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=8,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mlogloss'
        )
        xgb_model.fit(X_train, y_train, sample_weight=sample_weights)
        models['xgboost'] = xgb_model
        
        print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print()
        
        return models, X_train, y_train
    
    def evaluate_models(self, models, test_df, feature_cols):
        """ëª¨ë¸ í‰ê°€ (ì‹œê°„ ê¸°ë°˜ í…ŒìŠ¤íŠ¸)"""
        print("ğŸ“Š ëª¨ë¸ í‰ê°€ (ì‹œê°„ ê¸°ë°˜ í…ŒìŠ¤íŠ¸)...")
        
        X_test = test_df[feature_cols].fillna(0)
        y_test = test_df['whale_label']
        
        results = {}
        
        for model_name, model in models.items():
            print(f"\nğŸ” {model_name.upper()} í‰ê°€:")
            
            # ì˜ˆì¸¡
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)
            
            # ì •í™•ë„
            accuracy = (y_test == y_pred).mean()
            print(f"  ì •í™•ë„: {accuracy:.4f}")
            
            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
            from sklearn.metrics import f1_score, precision_recall_fscore_support
            
            f1_macro = f1_score(y_test, y_pred, average='macro')
            f1_weighted = f1_score(y_test, y_pred, average='weighted')
            
            print(f"  F1-Macro: {f1_macro:.4f}")
            print(f"  F1-Weighted: {f1_weighted:.4f}")
            
            # í´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥
            precision, recall, f1, support = precision_recall_fscore_support(
                y_test, y_pred, average=None
            )
            
            print("  í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
            for class_id in range(len(precision)):
                if class_id < len(test_df['whale_type'].unique()):
                    whale_types = test_df[test_df['whale_label'] == class_id]['whale_type']
                    if len(whale_types) > 0:
                        whale_type = whale_types.iloc[0]
                        whale_name = self.whale_definitions[whale_type]['name']
                        print(f"    {class_id} ({whale_name}): P={precision[class_id]:.3f}, "
                              f"R={recall[class_id]:.3f}, F1={f1[class_id]:.3f}, "
                              f"Support={support[class_id]}")
            
            results[model_name] = {
                'model': model,
                'accuracy': accuracy,
                'f1_macro': f1_macro,
                'f1_weighted': f1_weighted,
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'support': support
            }
        
        return results
    
    def analyze_feature_importance(self, models, feature_cols):
        """í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"""
        print("\nğŸ” í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„...")
        
        plt.figure(figsize=(15, 10))
        
        for i, (model_name, model) in enumerate(models.items()):
            plt.subplot(2, 1, i+1)
            
            if hasattr(model, 'feature_importances_'):
                importance = model.feature_importances_
            else:
                continue
                
            # ìƒìœ„ 15ê°œ í”¼ì²˜ë§Œ í‘œì‹œ
            indices = np.argsort(importance)[-15:]
            
            plt.barh(range(len(indices)), importance[indices])
            plt.yticks(range(len(indices)), [feature_cols[i] for i in indices])
            plt.title(f'{model_name.upper()} í”¼ì²˜ ì¤‘ìš”ë„ (ìƒìœ„ 15ê°œ)', fontsize=14, fontweight='bold')
            plt.xlabel('ì¤‘ìš”ë„')
        
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” ì €ì¥: {self.results_dir}/feature_importance.png")
    
    def create_confusion_matrix(self, results, test_df):
        """í˜¼ë™ í–‰ë ¬ ìƒì„±"""
        print("\nğŸ“Š í˜¼ë™ í–‰ë ¬ ìƒì„±...")
        
        fig, axes = plt.subplots(1, 2, figsize=(20, 8))
        
        for i, (model_name, result) in enumerate(results.items()):
            y_test = test_df['whale_label']
            y_pred = result['y_pred']
            
            cm = confusion_matrix(y_test, y_pred)
            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
            
            # í´ë˜ìŠ¤ ì´ë¦„ ìƒì„±
            class_names = []
            for class_id in range(len(cm)):
                whale_types = test_df[test_df['whale_label'] == class_id]['whale_type']
                if len(whale_types) > 0:
                    whale_type = whale_types.iloc[0]
                    whale_name = self.whale_definitions[whale_type]['name']
                    class_names.append(f'{class_id}\n{whale_name}')
                else:
                    class_names.append(f'{class_id}')
            
            sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',
                       xticklabels=class_names, yticklabels=class_names,
                       ax=axes[i])
            
            axes[i].set_title(f'{model_name.upper()} í˜¼ë™ í–‰ë ¬', fontsize=14, fontweight='bold')
            axes[i].set_xlabel('ì˜ˆì¸¡ í´ë˜ìŠ¤')
            axes[i].set_ylabel('ì‹¤ì œ í´ë˜ìŠ¤')
        
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… í˜¼ë™ í–‰ë ¬ ì €ì¥: {self.results_dir}/confusion_matrix.png")
    
    def run_full_pipeline(self, data_path='data/1000btc.csv'):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ ê³ ë˜ ê±°ë˜ íƒì§€ ì‹œìŠ¤í…œ v2.0 - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
        print("=" * 60)
        
        # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = self.load_and_prepare_data(data_path)
        
        # 2. ë„ë©”ì¸ ê¸°ë°˜ ë¼ë²¨ ìƒì„±
        df = self.create_domain_based_labels(df)
        
        # 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        df, feature_cols = self.engineer_features(df)
        
        # 4. ì‹œê°„ ê¸°ë°˜ ë¶„í• 
        train_df, test_df = self.time_based_split(df)
        
        # 5. ëª¨ë¸ í›ˆë ¨
        models, X_train, y_train = self.train_models(train_df, feature_cols)
        
        # 6. ëª¨ë¸ í‰ê°€
        results = self.evaluate_models(models, test_df, feature_cols)
        
        # 7. í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
        self.analyze_feature_importance(models, feature_cols)
        
        # 8. í˜¼ë™ í–‰ë ¬ ìƒì„±
        self.create_confusion_matrix(results, test_df)
        
        # 9. ìµœì¢… ê²°ê³¼ ìš”ì•½
        print("\nğŸ¯ ìµœì¢… ê²°ê³¼ ìš”ì•½:")
        print("=" * 40)
        
        best_model = None
        best_score = 0
        
        for model_name, result in results.items():
            accuracy = result['accuracy']
            f1_macro = result['f1_macro']
            
            print(f"ğŸ“Š {model_name.upper()}:")
            print(f"  ì •í™•ë„: {accuracy:.1%}")
            print(f"  F1-Macro: {f1_macro:.4f}")
            
            if f1_macro > best_score:
                best_score = f1_macro
                best_model = model_name
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model.upper()} (F1-Macro: {best_score:.4f})")
        
        # ëª¨ë¸ ì €ì¥
        import pickle
        model_save_path = f"{self.results_dir}/best_model.pkl"
        with open(model_save_path, 'wb') as f:
            pickle.dump({
                'model': results[best_model]['model'],
                'feature_cols': feature_cols,
                'whale_definitions': self.whale_definitions,
                'performance': results[best_model]
            }, f)
        
        print(f"ğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥: {model_save_path}")
        
        return results, feature_cols

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    detector = WhaleDetectorV2()
    results, feature_cols = detector.run_full_pipeline()
    
    print("\nğŸ‰ ê³ ë˜ ê±°ë˜ íƒì§€ ì‹œìŠ¤í…œ v2.0 êµ¬ì¶• ì™„ë£Œ!")
    print("ì´ë²ˆì—ëŠ” í˜„ì‹¤ì ì´ê³  í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 