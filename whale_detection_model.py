"""
ğŸ‹ ë¹„íŠ¸ì½”ì¸ ê³ ë˜ íƒì§€ ë° ë¶„ë¥˜ ëª¨ë¸ (Random Forest)
================================================================
ìµœì í™”ëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ í”„ë¡œë•ì…˜ ë ˆë²¨ì˜ ê³ ë˜ íƒì§€ ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (classification_report, confusion_matrix, f1_score, 
                           precision_score, recall_score, accuracy_score, roc_auc_score)
import pickle
import json
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['AppleGothic', 'Malgun Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class WhaleDetectionModel:
    """
    ğŸ‹ ë¹„íŠ¸ì½”ì¸ ê³ ë˜ íƒì§€ ë° ë¶„ë¥˜ ëª¨ë¸
    
    ê¸°ëŠ¥:
    - 5ê°€ì§€ ê³ ë˜ ìœ í˜• ë¶„ë¥˜ (ìˆ˜ì§‘í˜•, ë¶„ì‚°í˜•, ê¸‰í–‰í˜•, ì§‘ì¤‘í˜•, ê±°ëŒ€í˜•)
    - ìµœì í™”ëœ Class Weight ì ìš©
    - êµì°¨ ê²€ì¦ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
    - ëª¨ë¸ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥
    - ì‹¤ì‹œê°„ ì˜ˆì¸¡ API
    """
    
    def __init__(self, model_dir='models/whale_detection'):
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)
        
        # ê³ ë˜ ë¶„ë¥˜ ì²´ê³„
        self.class_names = {
            0: 'ìˆ˜ì§‘í˜•ê³ ë˜',    # Input ë§ê³  Output ì ìŒ
            1: 'ë¶„ì‚°í˜•ê³ ë˜',    # Output ë§ê³  ë¶„ì‚°
            2: 'ê¸‰í–‰í˜•ê³ ë˜',    # ë†’ì€ ìˆ˜ìˆ˜ë£Œ
            3: 'ì§‘ì¤‘í˜•ê³ ë˜',    # ë†’ì€ ì§‘ì¤‘ë„
            4: 'ê±°ëŒ€í˜•ê³ ë˜'     # ê·¹ëŒ€ ê±°ë˜ëŸ‰
        }
        
        # ìµœì  Class Weight (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
        self.optimal_class_weights = {
            0: 5.0,   # ìˆ˜ì§‘í˜•ê³ ë˜
            1: 15.0,  # ë¶„ì‚°í˜•ê³ ë˜
            2: 15.0,  # ê¸‰í–‰í˜•ê³ ë˜
            3: 0.8,   # ì§‘ì¤‘í˜•ê³ ë˜
            4: 30.0   # ê±°ëŒ€í˜•ê³ ë˜
        }
        
        # ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬
        self.model = None
        self.scaler = None
        self.feature_columns = ['total_volume_btc', 'input_count', 'output_count', 'concentration', 'fee_btc']
        
        print("ğŸ‹ ê³ ë˜ íƒì§€ ë° ë¶„ë¥˜ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_dir}")
        print("ğŸ¯ ë¶„ë¥˜ ëŒ€ìƒ: 5ê°€ì§€ ê³ ë˜ ìœ í˜•")
        
    def load_data(self, data_path='analysis/step1_results/class_weight_results/optimized_whale_dataset.csv'):
        """ìµœì í™”ëœ ë°ì´í„°ì…‹ ë¡œë“œ"""
        print("ğŸ“Š ìµœì í™”ëœ ê³ ë˜ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        
        try:
            df = pd.read_csv(data_path)
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê±´")
            
            # í”¼ì²˜ì™€ ë ˆì´ë¸” ë¶„ë¦¬
            X = df[self.feature_columns].copy()
            y = df['whale_class'].copy()
            
            print(f"ğŸ“Š í”¼ì²˜ ìˆ˜: {len(self.feature_columns)}ê°œ")
            print(f"ğŸ·ï¸ í´ë˜ìŠ¤ ìˆ˜: {len(y.unique())}ê°œ")
            
            # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
            class_dist = y.value_counts().sort_index()
            total = len(y)
            print("\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
            for cls, count in class_dist.items():
                percentage = (count / total) * 100
                print(f"  í´ë˜ìŠ¤ {cls} ({self.class_names[cls]}): {count:,}ê±´ ({percentage:.1f}%)")
            
            return X, y
            
        except FileNotFoundError:
            print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
            print("ğŸ’¡ ë¨¼ì € step1_class_weight_adjustment.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None, None
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
            return None, None
    
    def prepare_data(self, X, y, test_size=0.2, random_state=42):
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• """
        print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í•  ì¤‘...")
        
        # ê²°ì¸¡ê°’ í™•ì¸
        missing_values = X.isnull().sum()
        if missing_values.any():
            print(f"âš ï¸ ê²°ì¸¡ê°’ ë°œê²¬: {missing_values[missing_values > 0].to_dict()}")
            X = X.fillna(0)
            print("âœ… ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ë¶„í•  (ê³„ì¸µí™”)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        print(f"ğŸ¯ í›ˆë ¨ ë°ì´í„°: {len(X_train):,}ê±´ ({(1-test_size)*100:.0f}%)")
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê±´ ({test_size*100:.0f}%)")
        
        # í‘œì¤€í™”
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # DataFrameìœ¼ë¡œ ë³€í™˜ (ì»¬ëŸ¼ëª… ìœ ì§€)
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=self.feature_columns)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=self.feature_columns)
        
        print("âœ… ë°ì´í„° í‘œì¤€í™” ì™„ë£Œ")
        
        return X_train_scaled, X_test_scaled, y_train, y_test
    
    def train_model(self, X_train, y_train, optimize_hyperparameters=True):
        """ëª¨ë¸ í›ˆë ¨ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í¬í•¨)"""
        print("\nğŸŒ³ Random Forest ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        if optimize_hyperparameters:
            print("âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì§„í–‰ ì¤‘...")
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
            param_grid = {
                'n_estimators': [100, 200, 300],
                'max_depth': [6, 8, 10, None],
                'min_samples_split': [20, 50, 100],
                'min_samples_leaf': [10, 20, 30],
                'max_features': ['sqrt', 'log2', None]
            }
            
            # ê¸°ë³¸ ëª¨ë¸
            base_model = RandomForestClassifier(
                random_state=42,
                class_weight=self.optimal_class_weights,
                bootstrap=True,
                oob_score=True,
                n_jobs=-1
            )
            
            # Grid Search with 3-Fold CV
            grid_search = GridSearchCV(
                base_model, 
                param_grid, 
                cv=3,  # ë°ì´í„°ê°€ í¬ë¯€ë¡œ 3-foldë¡œ ì¶•ì†Œ
                scoring='f1_macro',
                n_jobs=-1,
                verbose=1
            )
            
            print("ğŸ” ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ì¤‘... (ì•½ 5-10ë¶„ ì†Œìš”)")
            grid_search.fit(X_train, y_train)
            
            self.model = grid_search.best_estimator_
            
            print("âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!")
            print(f"ğŸ† ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")
            print(f"ğŸ“Š ìµœì  CV Score: {grid_search.best_score_:.4f}")
            
        else:
            print("âš™ï¸ ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í›ˆë ¨ ì¤‘...")
            
            # ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ìµœì  íŒŒë¼ë¯¸í„° ì‚¬ìš©
            self.model = RandomForestClassifier(
                n_estimators=200,
                max_depth=8,
                min_samples_split=50,
                min_samples_leaf=20,
                max_features='sqrt',
                random_state=42,
                class_weight=self.optimal_class_weights,
                bootstrap=True,
                oob_score=True,
                n_jobs=-1
            )
            
            self.model.fit(X_train, y_train)
            print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        print(f"ğŸŒ³ íŠ¸ë¦¬ ê°œìˆ˜: {self.model.n_estimators}")
        print(f"ğŸ“Š OOB Score: {self.model.oob_score_:.4f}")
        
        return self.model
    
    def evaluate_model(self, X_test, y_test, show_detailed_report=True):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        
        if self.model is None:
            print("âŒ í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € train_model()ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
        
        # ì˜ˆì¸¡
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.predict_proba(X_test)
        
        # ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ
        accuracy = accuracy_score(y_test, y_pred)
        f1_macro = f1_score(y_test, y_pred, average='macro')
        f1_weighted = f1_score(y_test, y_pred, average='weighted')
        precision_macro = precision_score(y_test, y_pred, average='macro')
        recall_macro = recall_score(y_test, y_pred, average='macro')
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        results = {
            'accuracy': accuracy,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted,
            'precision_macro': precision_macro,
            'recall_macro': recall_macro,
            'oob_score': self.model.oob_score_,
            'y_test': y_test,
            'y_pred': y_pred,
            'y_pred_proba': y_pred_proba,
            'confusion_matrix': confusion_matrix(y_test, y_pred),
            'classification_report': classification_report(y_test, y_pred, output_dict=True)
        }
        
        print("ğŸ“ˆ ì „ì²´ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"  ì •í™•ë„ (Accuracy): {accuracy:.4f}")
        print(f"  F1-Macro: {f1_macro:.4f}")
        print(f"  F1-Weighted: {f1_weighted:.4f}")
        print(f"  ì •ë°€ë„ (Precision): {precision_macro:.4f}")
        print(f"  ì¬í˜„ìœ¨ (Recall): {recall_macro:.4f}")
        print(f"  OOB Score: {self.model.oob_score_:.4f}")
        
        if show_detailed_report:
            print("\nğŸ“‹ í´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥:")
            print("-" * 60)
            for class_id in sorted(y_test.unique()):
                class_report = results['classification_report'][str(class_id)]
                print(f"í´ë˜ìŠ¤ {class_id} ({self.class_names[class_id]}):")
                print(f"  Precision: {class_report['precision']:.4f}")
                print(f"  Recall: {class_report['recall']:.4f}")
                print(f"  F1-Score: {class_report['f1-score']:.4f}")
                print(f"  Support: {class_report['support']}")
                print()
        
        return results
    
    def cross_validate(self, X, y, cv_folds=5):
        """êµì°¨ ê²€ì¦ ìˆ˜í–‰"""
        print(f"\nğŸ”„ {cv_folds}-Fold êµì°¨ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")
        
        if self.model is None:
            print("âŒ í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ê³„ì¸µí™” êµì°¨ ê²€ì¦
        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)
        
        # ì—¬ëŸ¬ ì§€í‘œë¡œ êµì°¨ ê²€ì¦
        scoring_metrics = ['accuracy', 'f1_macro', 'f1_weighted', 'precision_macro', 'recall_macro']
        cv_results = {}
        
        for metric in scoring_metrics:
            scores = cross_val_score(self.model, X, y, cv=cv, scoring=metric, n_jobs=-1)
            cv_results[metric] = {
                'mean': scores.mean(),
                'std': scores.std(),
                'scores': scores
            }
            print(f"  {metric}: {scores.mean():.4f} (Â±{scores.std()*2:.4f})")
        
        return cv_results
    
    def get_feature_importance(self, plot=True):
        """í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"""
        print("\nğŸ“Š í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„...")
        
        if self.model is None:
            print("âŒ í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # í”¼ì²˜ ì¤‘ìš”ë„
        importance_df = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("ğŸ” í”¼ì²˜ ì¤‘ìš”ë„ ìˆœìœ„:")
        for idx, row in importance_df.iterrows():
            print(f"  {row['feature']}: {row['importance']:.4f}")
        
        if plot:
            plt.figure(figsize=(10, 6))
            sns.barplot(data=importance_df, x='importance', y='feature', palette='viridis')
            plt.title('ê³ ë˜ ë¶„ë¥˜ í”¼ì²˜ ì¤‘ìš”ë„', fontsize=14, fontweight='bold')
            plt.xlabel('ì¤‘ìš”ë„')
            plt.ylabel('í”¼ì²˜')
            
            # ê°’ í‘œì‹œ
            for idx, (importance, feature) in enumerate(zip(importance_df['importance'], importance_df['feature'])):
                plt.text(importance + 0.01, idx, f'{importance:.3f}', va='center')
            
            plt.tight_layout()
            plt.savefig(f'{self.model_dir}/feature_importance.png', dpi=300, bbox_inches='tight')
            plt.show()
            print(f"ğŸ“Š í”¼ì²˜ ì¤‘ìš”ë„ ì°¨íŠ¸ ì €ì¥: {self.model_dir}/feature_importance.png")
        
        return importance_df
    
    def create_visualizations(self, results):
        """ì„±ëŠ¥ ì‹œê°í™”"""
        print("\nğŸ“Š ì„±ëŠ¥ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. í˜¼ë™ í–‰ë ¬
        cm = results['confusion_matrix']
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', ax=ax1,
                    xticklabels=[f'{i}\n({self.class_names[i]})' for i in range(len(cm))],
                    yticklabels=[f'{i}\n({self.class_names[i]})' for i in range(len(cm))])
        ax1.set_title('ì •ê·œí™”ëœ í˜¼ë™ í–‰ë ¬', fontsize=12, fontweight='bold')
        ax1.set_xlabel('ì˜ˆì¸¡ í´ë˜ìŠ¤')
        ax1.set_ylabel('ì‹¤ì œ í´ë˜ìŠ¤')
        
        # 2. í´ë˜ìŠ¤ë³„ F1-Score
        class_f1_scores = []
        class_labels = []
        for class_id in sorted(results['y_test'].unique()):
            f1 = results['classification_report'][str(class_id)]['f1-score']
            class_f1_scores.append(f1)
            class_labels.append(f'{class_id}\n{self.class_names[class_id]}')
        
        bars = ax2.bar(class_labels, class_f1_scores, color=['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightpink'])
        ax2.set_title('í´ë˜ìŠ¤ë³„ F1-Score', fontsize=12, fontweight='bold')
        ax2.set_ylabel('F1-Score')
        ax2.set_ylim(0, 1.0)
        
        # ê°’ í‘œì‹œ
        for bar, score in zip(bars, class_f1_scores):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{score:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 3. í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬
        y_test_counts = pd.Series(results['y_test']).value_counts().sort_index()
        y_pred_counts = pd.Series(results['y_pred']).value_counts().sort_index()
        
        x = np.arange(len(y_test_counts))
        width = 0.35
        
        ax3.bar(x - width/2, y_test_counts.values, width, label='ì‹¤ì œ', alpha=0.7)
        ax3.bar(x + width/2, y_pred_counts.values, width, label='ì˜ˆì¸¡', alpha=0.7)
        ax3.set_title('í´ë˜ìŠ¤ë³„ ì‹¤ì œ vs ì˜ˆì¸¡ ë¶„í¬', fontsize=12, fontweight='bold')
        ax3.set_xlabel('í´ë˜ìŠ¤')
        ax3.set_ylabel('ê°œìˆ˜')
        ax3.set_xticks(x)
        ax3.set_xticklabels([f'{i}\n{self.class_names[i]}' for i in y_test_counts.index])
        ax3.legend()
        
        # 4. ì„±ëŠ¥ ì§€í‘œ ë ˆì´ë” ì°¨íŠ¸
        metrics = ['ì •í™•ë„', 'F1-Macro', 'F1-Weighted', 'ì •ë°€ë„', 'ì¬í˜„ìœ¨']
        values = [
            results['accuracy'],
            results['f1_macro'], 
            results['f1_weighted'],
            results['precision_macro'],
            results['recall_macro']
        ]
        
        # ë ˆì´ë” ì°¨íŠ¸ë¥¼ ìœ„í•œ ê°ë„ ê³„ì‚°
        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
        values += [values[0]]  # ë‹«íŒ ë„í˜•ì„ ìœ„í•´
        angles += [angles[0]]
        
        ax4 = plt.subplot(2, 2, 4, projection='polar')
        ax4.plot(angles, values, 'o-', linewidth=2, color='blue')
        ax4.fill(angles, values, alpha=0.25, color='blue')
        ax4.set_xticks(angles[:-1])
        ax4.set_xticklabels(metrics)
        ax4.set_ylim(0, 1)
        ax4.set_title('ì „ì²´ ì„±ëŠ¥ ì§€í‘œ', fontsize=12, fontweight='bold', pad=20)
        
        plt.tight_layout()
        plt.savefig(f'{self.model_dir}/model_performance.png', dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ğŸ“Š ì„±ëŠ¥ ì‹œê°í™” ì €ì¥: {self.model_dir}/model_performance.png")
    
    def save_model(self):
        """ëª¨ë¸ ì €ì¥"""
        print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
        
        if self.model is None or self.scaler is None:
            print("âŒ ì €ì¥í•  ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            # ëª¨ë¸ ì €ì¥
            model_file = f'{self.model_dir}/whale_detection_model.pkl'
            with open(model_file, 'wb') as f:
                pickle.dump(self.model, f)
            print(f"âœ… ëª¨ë¸ ì €ì¥: {model_file}")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
            scaler_file = f'{self.model_dir}/feature_scaler.pkl'
            with open(scaler_file, 'wb') as f:
                pickle.dump(self.scaler, f)
            print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥: {scaler_file}")
            
            # ëª¨ë¸ ì„¤ì • ì €ì¥
            config = {
                'class_names': self.class_names,
                'optimal_class_weights': self.optimal_class_weights,
                'feature_columns': self.feature_columns,
                'model_type': 'RandomForestClassifier',
                'created_at': datetime.now().isoformat(),
                'model_parameters': self.model.get_params()
            }
            
            config_file = f'{self.model_dir}/model_config.json'
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            print(f"âœ… ì„¤ì • ì €ì¥: {config_file}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load_model(self):
        """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        print("\nğŸ“‚ ì €ì¥ëœ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            model_file = f'{self.model_dir}/whale_detection_model.pkl'
            with open(model_file, 'rb') as f:
                self.model = pickle.load(f)
            print(f"âœ… ëª¨ë¸ ë¡œë“œ: {model_file}")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            scaler_file = f'{self.model_dir}/feature_scaler.pkl'
            with open(scaler_file, 'rb') as f:
                self.scaler = pickle.load(f)
            print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ: {scaler_file}")
            
            # ì„¤ì • ë¡œë“œ
            config_file = f'{self.model_dir}/model_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # JSONì—ì„œ ë¡œë“œí•œ class_namesì˜ í‚¤ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            self.class_names = {int(k): v for k, v in config['class_names'].items()}
            # optimal_class_weightsì˜ í‚¤ë„ ì •ìˆ˜ë¡œ ë³€í™˜
            self.optimal_class_weights = {int(k): v for k, v in config['optimal_class_weights'].items()}
            self.feature_columns = config['feature_columns']
            
            print(f"âœ… ì„¤ì • ë¡œë“œ: {config_file}")
            print(f"ğŸ“… ëª¨ë¸ ìƒì„±ì¼: {config.get('created_at', 'Unknown')}")
            
            return True
            
        except FileNotFoundError as e:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return False
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def predict(self, X, return_proba=False):
        """ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡"""
        if self.model is None or self.scaler is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        # DataFrameì´ ì•„ë‹Œ ê²½ìš° ë³€í™˜
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X, columns=self.feature_columns)
        
        # í”¼ì²˜ ìˆœì„œ í™•ì¸
        X = X[self.feature_columns]
        
        # í‘œì¤€í™”
        X_scaled = self.scaler.transform(X)
        
        # ì˜ˆì¸¡
        predictions = self.model.predict(X_scaled)
        
        if return_proba:
            probabilities = self.model.predict_proba(X_scaled)
            return predictions, probabilities
        
        return predictions
    
    def predict_single(self, total_volume_btc, input_count, output_count, concentration, fee_btc, show_details=True):
        """ë‹¨ì¼ ê±°ë˜ ì˜ˆì¸¡ (ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ì¸í„°í˜ì´ìŠ¤)"""
        
        # ì…ë ¥ ë°ì´í„° ìƒì„±
        data = pd.DataFrame({
            'total_volume_btc': [total_volume_btc],
            'input_count': [input_count],
            'output_count': [output_count],
            'concentration': [concentration],
            'fee_btc': [fee_btc]
        })
        
        # ì˜ˆì¸¡
        prediction, probabilities = self.predict(data, return_proba=True)
        
        predicted_class = prediction[0]
        predicted_name = self.class_names[predicted_class]
        confidence = probabilities[0][predicted_class]
        
        if show_details:
            print(f"\nğŸ” ê³ ë˜ ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼:")
            print(f"ğŸ“Š ì…ë ¥ ë°ì´í„°:")
            print(f"  ì´ ê±°ë˜ëŸ‰: {total_volume_btc:,.0f} BTC")
            print(f"  Input ê°œìˆ˜: {input_count}")
            print(f"  Output ê°œìˆ˜: {output_count}")
            print(f"  ì§‘ì¤‘ë„: {concentration:.4f}")
            print(f"  ìˆ˜ìˆ˜ë£Œ: {fee_btc:.6f} BTC")
            print(f"\nğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
            print(f"  í´ë˜ìŠ¤: {predicted_class} ({predicted_name})")
            print(f"  ì‹ ë¢°ë„: {confidence:.4f} ({confidence*100:.1f}%)")
            print(f"\nğŸ“Š ê° í´ë˜ìŠ¤ë³„ í™•ë¥ :")
            for i, prob in enumerate(probabilities[0]):
                print(f"  í´ë˜ìŠ¤ {i} ({self.class_names[i]}): {prob:.4f} ({prob*100:.1f}%)")
        
        return {
            'predicted_class': predicted_class,
            'predicted_name': predicted_name,
            'confidence': confidence,
            'probabilities': probabilities[0],
            'input_data': data.iloc[0].to_dict()
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë¹„íŠ¸ì½”ì¸ ê³ ë˜ íƒì§€ ë° ë¶„ë¥˜ ëª¨ë¸ ê°œë°œ ì‹œì‘!")
    print("=" * 60)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    whale_model = WhaleDetectionModel()
    
    # ë°ì´í„° ë¡œë“œ
    X, y = whale_model.load_data()
    if X is None:
        return
    
    # ë°ì´í„° ì¤€ë¹„
    X_train, X_test, y_train, y_test = whale_model.prepare_data(X, y)
    
    # ëª¨ë¸ í›ˆë ¨ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì—¬ë¶€ ì„ íƒ)
    optimize = input("\nğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’: n): ").lower().strip()
    optimize_hyperparameters = optimize == 'y'
    
    whale_model.train_model(X_train, y_train, optimize_hyperparameters=optimize_hyperparameters)
    
    # ëª¨ë¸ í‰ê°€
    results = whale_model.evaluate_model(X_test, y_test)
    
    # êµì°¨ ê²€ì¦
    cv_results = whale_model.cross_validate(X, y)
    
    # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
    importance_df = whale_model.get_feature_importance(plot=True)
    
    # ì‹œê°í™”
    whale_model.create_visualizations(results)
    
    # ëª¨ë¸ ì €ì¥
    whale_model.save_model()
    
    print("\nğŸ‰ ëª¨ë¸ ê°œë°œ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… F1-Macro Score: {results['f1_macro']:.4f}")
    print(f"ğŸ“Š ìµœì¢… ì •í™•ë„: {results['accuracy']:.4f}")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {whale_model.model_dir}/")
    
    # ì˜ˆì‹œ ì˜ˆì¸¡
    print("\nğŸ” ì˜ˆì‹œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:")
    whale_model.predict_single(
        total_volume_btc=5000,
        input_count=1,
        output_count=2,
        concentration=0.99,
        fee_btc=0.001
    )

if __name__ == "__main__":
    main() 

    