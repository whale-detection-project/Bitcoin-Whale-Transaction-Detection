import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# ğŸ”¹ 1. ë°ì´í„° ë¡œë”©
train_df = pd.read_csv("dataset/1000btc_train.csv")
features = ['input_count', 'output_count', 'max_output_ratio', 'max_input_ratio']

# ğŸ”¹ 2. ì „ì²˜ë¦¬ (ë¡œê·¸ ë³€í™˜ + ì •ê·œí™”)
X_log = train_df[features].apply(lambda x: np.log1p(x))
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_log)

# ğŸ”¹ 3. ì—˜ë³´ìš° ë°©ë²•ìœ¼ë¡œ ìµœì  k ì°¾ê¸°
wcss = []  # í´ëŸ¬ìŠ¤í„° ë‚´ ì œê³±í•© (within-cluster sum of squares)

K_RANGE = range(1, 11)  # kë¥¼ 1ë¶€í„° 10ê¹Œì§€ ì‹¤í—˜

for k in K_RANGE:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)  # inertia_ = WCSS

# ê¸°ìš¸ê¸° ê¸°ë°˜ ìë™ íƒì§€
wcss_diff = np.diff(wcss)
wcss_diff2 = np.diff(wcss_diff)
optimal_k = np.argmax(wcss_diff2) + 2

plt.figure(figsize=(8, 4))
plt.plot(K_RANGE, wcss, marker='o')
plt.axvline(x=optimal_k, color='r', linestyle='--', label=f"Optimal k = {optimal_k}")
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of clusters (k)')
plt.ylabel('WCSS (Inertia)')
plt.legend()
plt.grid(True)
plt.show()

print(f"ğŸ“Œ ìë™ íƒì§€ëœ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜: k = {optimal_k}")

