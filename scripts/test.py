import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.decomposition import PCA
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score
)
from sklearn.manifold import TSNE
import umap.umap_ as umap
import xgboost as xgb
import os

# ðŸ”¹ 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
df = pd.read_csv("dataset/1000btc_test.csv")

# ðŸ”¹ 2. í”¼ì²˜ ì •ì˜
features = [
    'input_count', 'output_count', 'max_output_ratio'
    , 'max_input_ratio'
]

# ðŸ”¹ 3. ì „ì²˜ë¦¬: ë¡œê·¸ ë³€í™˜
X_log = df[features].apply(lambda x: np.log1p(x))

# ðŸ”¹ 4. ì „ì²˜ë¦¬ ë„êµ¬ ë¶ˆëŸ¬ì˜¤ê¸° (train ê¸°ì¤€)
scaler = joblib.load("model/scaler.pkl")
kmeans = joblib.load("model/kmeans.pkl")
pca = joblib.load("model/pca.pkl")

# ðŸ”¹ 5. ì •ê·œí™” ë° í´ëŸ¬ìŠ¤í„° ë¼ë²¨ ë¶€ì—¬ (train ê¸°ì¤€ìœ¼ë¡œ)
X_scaled = scaler.transform(X_log)
df['cluster_label'] = kmeans.predict(X_scaled)

# ðŸ”¹ 6. PCA 2D ì‹œê°í™” ë°ì´í„° ìƒì„±
X_pca = pca.transform(X_scaled)
df['pca1'], df['pca2'] = X_pca[:, 0], X_pca[:, 1]

# ðŸ”¹ 7. ëª¨ë¸ ë¡œë“œ (XGBoost)
xgb_model = xgb.XGBClassifier()
xgb_model.load_model("model/xgb_model.json")

# âœ… ì „ì²´ ë°ì´í„°ë¡œ ì˜ˆì¸¡
X = X_scaled
y_true = df['cluster_label']
y_pred = xgb_model.predict(X)

# ðŸ”¹ 8. ê²°ê³¼ ì €ìž¥ í´ë” ìƒì„±
os.makedirs("test", exist_ok=True)
with open("test/eval_result.txt", "w", encoding="utf-8") as f:
    f.write("ðŸ“Š [Confusion Matrix]\n")
    f.write(str(confusion_matrix(y_true, y_pred)) + "\n\n")

    f.write("ðŸ“‹ [Classification Report]\n")
    f.write(classification_report(y_true, y_pred) + "\n")

    acc = accuracy_score(y_true, y_pred)
    f.write(f"ðŸŽ¯ [Accuracy Score]\n{acc * 100:.2f}%\n\n")

    f.write("ðŸ“Š [Test Prediction Distribution]\n")
    unique, counts = np.unique(y_pred, return_counts=True)
    total = sum(counts)
    for label, count in zip(unique, counts):
        f.write(f"cluster {label}: {count:,}ê±´ ({(count / total) * 100:.2f}%)\n")
    
    f.write("\nðŸ” [í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ê°’ ë³µì› (ì›ëž˜ ë‹¨ìœ„)]\n")
    cluster_centers_scaled = kmeans.cluster_centers_
    cluster_centers_log = scaler.inverse_transform(cluster_centers_scaled)
    cluster_centers_orig = np.expm1(cluster_centers_log)  # log1p â†’ ì›ë³µ
    df_centers = pd.DataFrame(cluster_centers_orig, columns=features)
    df_centers.index.name = "cluster"
    f.write(df_centers.to_string(float_format='{:,.7f}'.format) + "\n")

    f.write("\nðŸ“Œ í´ëŸ¬ìŠ¤í„° í•´ì„\n")
    f.write("Cluster 0 : ì†Œìˆ˜ ìž…ë ¥ â†’ ì¤‘ê°„ ë‹¤ìˆ˜ ì¶œë ¥, ì§€ê°‘ ë¦¬ë°¸ëŸ°ì‹± ì¶”ì •\n")
    f.write("Cluster 1 : ë‹¨ì¼ ìž…ë ¥ â†’ ë‹¨ì¼ ì¶œë ¥, ì½œë“œì›”ë › or ê³ ì • ì „ì†¡\n")
    f.write("Cluster 2 : ë‹¤ìˆ˜ ìž…ë ¥ â†’ ì†Œìˆ˜ ì¶œë ¥, ìž…ë ¥ ë³‘í•© / Mixing ì¤€ë¹„\n")
    f.write("Cluster 3 : ì†Œìˆ˜ ìž…ë ¥ â†’ ë‹¤ìˆ˜ ì¶œë ¥, ì„¸íƒ ì˜ì‹¬ or ê±°ëž˜ì†Œ ì¶œê¸ˆ\n")

##
# ðŸ”¹ UMAP ì‹œê°í™”
reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
X_umap = reducer.fit_transform(X_scaled)

df['umap1'], df['umap2'] = X_umap[:, 0], X_umap[:, 1]

plt.figure(figsize=(10, 6))
sns.scatterplot(x='umap1', y='umap2', hue='cluster_label', data=df, palette='tab10', s=10)
plt.title("ðŸ–¼ UMAP Visualization with Cluster Labels")
plt.xlabel("UMAP 1")
plt.ylabel("UMAP 2")
plt.legend(title="Cluster", loc='upper right')
plt.tight_layout()
plt.savefig("test/umap_visualization.png", dpi=300)
plt.close()

# ðŸ”¹ t-SNE ì‹œê°í™”
tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)
X_tsne = tsne.fit_transform(X_scaled)

df['tsne1'], df['tsne2'] = X_tsne[:, 0], X_tsne[:, 1]

plt.figure(figsize=(10, 6))
sns.scatterplot(x='tsne1', y='tsne2', hue='cluster_label', data=df, palette='tab10', s=10)
plt.title("ðŸ–¼ t-SNE Visualization with Cluster Labels")
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.legend(title="Cluster", loc='upper right')
plt.tight_layout()
plt.savefig("test/tsne_visualization.png", dpi=300)
plt.close()

# ðŸ”¹ 9. PCA ì‹œê°í™”
# plt.figure(figsize=(10, 6))
# sns.scatterplot(x=df['pca1'], y=df['pca2'], hue=df['cluster_label'], palette='tab10', s=10)
# plt.title("ðŸ–¼ PCA Visualization with Cluster Labels")
# plt.xlabel("PCA 1")
# plt.ylabel("PCA 2")
# plt.legend(title="Cluster", loc='upper right')
# plt.tight_layout()
# plt.savefig("test/pca_visualization.png", dpi=300)
# plt.close()

## í”¼ì³ë³„ ì¤‘ìš”ë„ ë¶„ì„
feature_names = ['input_count', 'output_count', 'max_output_ratio', 'max_input_ratio']
booster = xgb_model.get_booster()

importance_types = ['gain', 'weight', 'cover']

with open("test/eval_result.txt", "a", encoding="utf-8") as f:
    for importance_type in importance_types:
        scores = booster.get_score(importance_type=importance_type)

        total_score = sum(scores.values())
        combined = []

        for fid, score in scores.items():
            index = int(fid[1:])
            fname = feature_names[index]
            ratio = (score / total_score) * 100 if total_score > 0 else 0
            combined.append((fname, score, ratio))

        combined.sort(key=lambda x: x[1], reverse=True)

        f.write(f"\nðŸ“ˆ [Feature Importance - by {importance_type.title()}]\n")
        for name, score, ratio in combined:
            f.write(f"{name}: {score:.4f} ({ratio:.2f}%)\n")
