from crawl4ai import crawl_and_extract
import pandas as pd

# ğŸ“¡ í¬ë¡¤ë§í•  í˜ì´ì§€ URL ëª©ë¡ ìƒì„±
base_url = "https://bitinfocharts.com/top-100-richest-bitcoin-addresses"
urls = [base_url + ".html"] + [f"{base_url}-{i}.html" for i in range(2, 11)]

# ğŸ“¥ ë°ì´í„° í¬ë¡¤ë§
results = crawl_and_extract(
    urls=urls,
    extraction_type="table",
    table_index=0,
    include_raw_html=False,
)

# ğŸ§¹ ì •ì œ ë° í•„í„°ë§
all_data = []
for page in results:
    if not page['tables']:
        continue
    df = page['tables'][0]
    df.columns = [
        "Rank", "Address", "Balance", "% of coins", "First In", "Last In",
        "Ins", "First Out", "Last Out", "Outs"
    ]
    df["Balance"] = df["Balance"].str.replace(r"[^\d.]", "", regex=True).astype(float)
    df = df[df["Balance"] >= 1000]
    all_data.append(df)

# ğŸ”— í†µí•© ë° ì €ì¥
df_all = pd.concat(all_data, ignore_index=True)
df_all.to_csv("top_btc_wallets_over_1000btc.csv", index=False)
print("âœ… ì €ì¥ ì™„ë£Œ: top_btc_wallets_over_1000btc.csv")
