"""
Test script Â·  PyTorch MLP + ê±°ë¦¬ ì»·ì˜¤í”„(Ï„)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ìŠ¤ì¼€ì¼ëŸ¬ Â· Ï„ Â· PyTorch ëª¨ë¸ ë¡œë“œ
â€¢ í…ŒìŠ¤íŠ¸ì…‹ ì „ì²˜ë¦¬ â†’ Unknown(4) íŒì • â†’ ì˜ˆì¸¡ Â· í‰ê°€
â€¢ ì „ì²´ ê²°ê³¼ CSV + Unknown ì „ìš© CSV **ë‘˜ ë‹¤** ì €ì¥
"""

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from pathlib import Path
from scipy.spatial.distance import cdist
from sklearn.metrics import (
    balanced_accuracy_score,
    classification_report,
    confusion_matrix,
)
import joblib

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ê²½ë¡œ ì„¤ì •
MODEL_DIR = Path("model")
DATA_PATH = Path("dataset/1000btc_test.csv")
OUT_DIR   = Path("test"); OUT_DIR.mkdir(exist_ok=True)

FEATURES = ["input_count", "output_count", "max_output_ratio", "max_input_ratio"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ëª¨ë¸ ì •ì˜ & ë¡œë“œ
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(4, 256), nn.ReLU(),
            nn.Linear(256, 128), nn.ReLU(),
            nn.Linear(128, 64),  nn.ReLU(),
            nn.Linear(64, 32),   nn.ReLU(),
            nn.Linear(32, 4)
        )
    def forward(self, x): return self.net(x)

model = MLP()
model.load_state_dict(torch.load(MODEL_DIR / "mlp4_torch.pt", map_location="cpu"))
model.eval()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ì „ì²˜ë¦¬ ì •ë³´ ë¡œë“œ
scaler = joblib.load(MODEL_DIR / "scaler_np.pkl")
centers_tau = joblib.load(MODEL_DIR / "km_tau.pkl")
mean_, std_ = scaler["mean"], scaler["std"]
centers, tau = centers_tau["centers"], centers_tau["tau"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬
df = pd.read_csv(DATA_PATH)
X_raw = df[FEATURES].values
X_log = np.log1p(X_raw)
X_scaled = (X_log - mean_) / std_

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. ì°¸ê°’ ìƒì„± (KMeans ì¤‘ì‹¬ ê¸°ì¤€)
y_true = np.argmin(cdist(X_scaled, centers), axis=1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. MLP ì˜ˆì¸¡ + Ï„ ì»·ì˜¤í”„
X_tensor = torch.tensor(X_scaled, dtype=torch.float32)
with torch.no_grad():
    mlp_pred = model(X_tensor).argmax(1).numpy()

d_min = cdist(X_scaled, centers).min(1)
y_pred = np.where(d_min > tau, 4, mlp_pred)  # Unknown=4

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. í‰ê°€ ì§€í‘œ (inlier ê¸°ì¤€)
unknown_mask = (y_pred == 4)
idx_in = ~unknown_mask

print(f"ğŸŸ¡ Unknown(4) ìƒ˜í”Œ ìˆ˜ : {unknown_mask.sum()} / {len(df)}"
      f"  ({unknown_mask.mean()*100:.2f} %)")

print("\nğŸ“Š  Balanced Accuracy (inlier):",
      balanced_accuracy_score(y_true[idx_in], y_pred[idx_in]))

print("\nğŸ“Š  Confusion Matrix (inlier)\n",
      confusion_matrix(y_true[idx_in], y_pred[idx_in]))

print("\nğŸ“Š  Classification Report (inlier)\n",
      classification_report(y_true[idx_in], y_pred[idx_in], digits=4))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8-A. ì „ì²´ ê²°ê³¼ ì €ì¥
out_all = pd.DataFrame({
    "idx": df.index,
    "true_cluster": y_true,
    "pred_cluster": y_pred,
    "d_min": d_min
})
out_all.to_csv(OUT_DIR / "mlp4_tau_predictions.csv", index=False)
print(f"\nâœ… ì „ì²´ CSV ì €ì¥ â†’ {OUT_DIR/'mlp4_tau_predictions.csv'}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8-B. Unknown ì „ìš© CSV
df_unknown = df.loc[unknown_mask].assign(
    predicted_cluster=y_pred[unknown_mask],
    d_min=d_min[unknown_mask]
)
df_unknown.to_csv(OUT_DIR / "mlp4_tau_unknowns.csv", index=False)
print(f"âœ… Unknown CSV ì €ì¥ â†’ {OUT_DIR/'mlp4_tau_unknowns.csv'}")
