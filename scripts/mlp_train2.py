"""
Oversampling + 4-layer MLP  (PyTorch / SciPy ë§Œ ì‚¬ìš©)

â€¢  ë¡œê·¸+í‘œì¤€í™”(ìˆ˜ì‘ì—…) â†’ SciPy K-Means ë¡œ ì„ì‹œ ë¼ë²¨
â€¢  í´ë˜ìŠ¤ ë¶ˆê· í˜•: numpy ë¡œ ê°„ë‹¨ Random oversampling
â€¢  PyTorch ë¡œ 256-128-64-32 MLP í•™ìŠµ, Early-Stopping(25 epoch patience)
â€¢  Ï„(99.5-percentile) ì»·ì˜¤í”„ ê³„ì‚° â†’ centers, Ï„ ì €ì¥

í•„ìˆ˜ pip: pandas numpy scipy torch joblib
"""

import numpy as np, pandas as pd, torch, torch.nn as nn
from pathlib import Path
from scipy.cluster.vq import kmeans2            # SciPy K-Means
from scipy.spatial.distance import cdist
import joblib, time, random, os

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ë°ì´í„° ë¡œë“œ
df       = pd.read_csv("dataset/1000btc_train.csv")
FEAT     = ["input_count","output_count","max_output_ratio","max_input_ratio"]
X_log    = np.log1p(df[FEAT].values)           # (N,4)

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ìˆ˜ì‘ì—… StandardScaler
mean_, std_ = X_log.mean(0), X_log.std(0)
X_scaled    = (X_log - mean_) / std_

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. K-Means ë¼ë²¨ (k=4)
centers, labels = kmeans2(X_scaled, k=4, minit="++", iter=100, seed=42)
y = labels.astype(np.int64)

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Random Oversampling (ê°„ë‹¨ êµ¬í˜„)
class_counts = np.bincount(y)
max_count    = class_counts.max()
idx_all      = np.hstack([
    np.random.choice(np.where(y==k)[0], size=max_count, replace=True)
    for k in range(4)
])
np.random.shuffle(idx_all)
X_bal, y_bal = X_scaled[idx_all], y[idx_all]

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Train / Val split (80/20)
split = int(0.8 * len(X_bal))
X_tr, X_val = X_bal[:split], X_bal[split:]
y_tr, y_val = y_bal[:split], y_bal[split:]

# Torch Tensor
Xtr = torch.tensor(X_tr,  dtype=torch.float32)
ytr = torch.tensor(y_tr,  dtype=torch.long)
Xva = torch.tensor(X_val, dtype=torch.float32)
yva = torch.tensor(y_val, dtype=torch.long)

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. 4-Layer MLP ì •ì˜
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(4,256), nn.ReLU(),
            nn.Linear(256,128), nn.ReLU(),
            nn.Linear(128,64),  nn.ReLU(),
            nn.Linear(64,32),   nn.ReLU(),
            nn.Linear(32,4)
        )
    def forward(self,x): return self.net(x)

model = MLP()
optim = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
crit  = nn.CrossEntropyLoss()
BATCH = 256
PATIENCE=25
best_val, patience = 1e9, 0

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. í•™ìŠµ loop + EarlyStopping
t0=time.time()
for epoch in range(400):
    # mini-batch shuffle
    idx = torch.randperm(len(Xtr))
    for s in range(0,len(idx),BATCH):
        xb = Xtr[idx[s:s+BATCH]]
        yb = ytr[idx[s:s+BATCH]]
        optim.zero_grad()
        loss = crit(model(xb), yb)
        loss.backward(); optim.step()

    # validation
    with torch.no_grad():
        val_loss = crit(model(Xva), yva).item()
    if val_loss < best_val - 1e-4:
        best_val = val_loss; patience = 0
    else:
        patience += 1
    print(f"Epoch {epoch:3d}  train-loss {loss.item():.4f}  val {val_loss:.4f}")
    if patience >= PATIENCE: break
print("âœ… finished in", time.time()-t0,"sec   best-val",best_val)

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8. Ï„ (99.5%) ì¹˜í™˜ê³± ê³„ì‚°
d_min = cdist(X_scaled, centers).min(1)
tau   = np.percentile(d_min, 99.5)
print("Ï„ =", tau)

# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 9. ì €ì¥
mdl_dir = Path("model"); mdl_dir.mkdir(exist_ok=True)
torch.save(model.state_dict(), mdl_dir/"mlp4_torch.pt")
joblib.dump({"mean":mean_, "std":std_}, mdl_dir/"scaler_np.pkl")
joblib.dump({"centers":centers, "tau":tau}, mdl_dir/"km_tau.pkl")
print("ğŸ“¦ saved â†’", mdl_dir.resolve())
